{"meta":{"version":1,"warehouse":"1.0.3"},"models":{"Asset":[{"_id":"themes/even/source/js/zepto.min.js","path":"js/zepto.min.js","modified":1},{"_id":"themes/even/source/js/theme.js","path":"js/theme.js","modified":1},{"_id":"themes/even/source/fonts/iconfont/iconfont.woff2","path":"fonts/iconfont/iconfont.woff2","modified":1},{"_id":"themes/even/source/fonts/iconfont/iconfont.woff","path":"fonts/iconfont/iconfont.woff","modified":1},{"_id":"themes/even/source/fonts/iconfont/iconfont.ttf","path":"fonts/iconfont/iconfont.ttf","modified":1},{"_id":"themes/even/source/fonts/iconfont/iconfont.svg","path":"fonts/iconfont/iconfont.svg","modified":1},{"_id":"themes/even/source/fonts/iconfont/iconfont.eot","path":"fonts/iconfont/iconfont.eot","modified":1},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.woff2","path":"fonts/chancery/apple-chancery-webfont.woff2","modified":1},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.woff","path":"fonts/chancery/apple-chancery-webfont.woff","modified":1},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.ttf","path":"fonts/chancery/apple-chancery-webfont.ttf","modified":1},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.svg","path":"fonts/chancery/apple-chancery-webfont.svg","modified":1},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.eot","path":"fonts/chancery/apple-chancery-webfont.eot","modified":1},{"_id":"themes/even/source/favicon.ico","path":"favicon.ico","modified":1},{"_id":"themes/even/source/css/style.scss","path":"css/style.scss","modified":1}],"Cache":[{"_id":"source/_posts/Build-rest-api.md","shasum":"72aacce2070ee0d6553b745a10d8f8a38dea4ebe","modified":1479981076000},{"_id":"source/_posts/Dubbo学习-理解动态代理.md","shasum":"6ff49fe28bfe99b4177a40cc630e1777b33f675c","modified":1479980997000},{"_id":"source/_posts/Git查看、删除、重命名远程分支和tag.md","shasum":"4c96b2b4830cea0616aa8739f159848be429918a","modified":1479981087000},{"_id":"source/_posts/RESTAPI-Reference.md","shasum":"4ec8d37fd9625a964299e77494797c09cd9610a4","modified":1454475025000},{"_id":"source/_posts/Spring可扩展的XML配置.md","shasum":"080618ec7ab2387e14ae487cf55089ae6b9c5a61","modified":1479981052000},{"_id":"source/_posts/bootcamp.md","shasum":"fbcc02e4e8bc51e6bfe0fc62868dcc80259cf6b7","modified":1479981275000},{"_id":"source/_posts/effective-java-methods.md","shasum":"43930f28d43f63ee3b4f4bcdec29b4df3398f7cf","modified":1479981134000},{"_id":"source/_posts/how-to-create-products-customers-love.md","shasum":"55c5b8a40fa1a218b6d79537bc6c4d86205a7090","modified":1479981145000},{"_id":"source/_posts/深入理解HashMap.md","shasum":"c9e80d01d02fafc33f4072cf50349a5ef58c9da3","modified":1479981163000},{"_id":"source/about/index.md","shasum":"aab4282e09cb2d7c2da049f6e19ad5c527e3c9ec","modified":1479980820000},{"_id":"source/categories/index.md","shasum":"65fb4ecf973cc0f0edec435ff874ca1b7b3f6910","modified":1479980632000},{"_id":"source/tags/index.md","shasum":"59361c960c21867ab4df450369960f8530a7cfaf","modified":1479980699000},{"_id":"themes/even/source/css/_setting.scss","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1479979528000},{"_id":"themes/even/LICENSE","shasum":"65da563ec8598aecdbf3f49968b85a117543ac54","modified":1479979528000},{"_id":"themes/even/README.md","shasum":"7d0cc1952dc6671700ef0434ebff57ced2843e75","modified":1479979528000},{"_id":"themes/even/_config.yml","shasum":"1f9eb45acf6ca7d0b27ebd1289e7ea3b7005f568","modified":1479982485000},{"_id":"themes/even/_config.yml.sample","shasum":"90c0085e101874b8415e14a5ab4bc76fd5f6163b","modified":1479979528000},{"_id":"themes/even/doc/doc_en.md","shasum":"9518231e1f9d9d82ec0781275f4b92240f2b70e7","modified":1479979528000},{"_id":"themes/even/doc/doc_zh.md","shasum":"cb4321c1f492efe9d2545ef69c4606df2b8d638a","modified":1479979528000},{"_id":"themes/even/languages/default.yml","shasum":"0e1c336886a5b31d592bccc07a3e978a28de5318","modified":1479979528000},{"_id":"themes/even/languages/en.yml","shasum":"7edcef06e5a8307e81e1625c61a3e06bedcd9faf","modified":1479979528000},{"_id":"themes/even/languages/fr-fr.yml","shasum":"30b1b5712fcaec8424b34c50af9030538c36a066","modified":1479979528000},{"_id":"themes/even/languages/ru.yml","shasum":"0fd880e9292ab3015ceab359587a458aa7483db2","modified":1479979528000},{"_id":"themes/even/languages/zh-cn.yml","shasum":"2e717b38a271e27e22ac107d925f19b7c0ce4a7f","modified":1479979528000},{"_id":"themes/even/layout/about.jade","shasum":"2826aa452d3ff1e6aa37f6862fcc11f61c1d68d1","modified":1479979528000},{"_id":"themes/even/layout/archive.jade","shasum":"0f5127dbc963d676bc6331b1b5ed49c22c8122bf","modified":1479979528000},{"_id":"themes/even/layout/categories.jade","shasum":"80d95fcc7f4209e9eb7a2de4be33d2e3b83dff1b","modified":1479979528000},{"_id":"themes/even/layout/index.jade","shasum":"bb47055acff9f0f78e3da3b1b8597658523cc990","modified":1479979528000},{"_id":"themes/even/layout/mixins/analytics.jade","shasum":"e4650d862d74e7e60cb6532b570fe1c59d2e6a94","modified":1479979528000},{"_id":"themes/even/layout/mixins/categories.jade","shasum":"25bf2fb3576cb5ab405f1049c76f9a40721408f6","modified":1479979528000},{"_id":"themes/even/layout/mixins/comment.jade","shasum":"b941c45bcc77799137a98361676b192c147efe1c","modified":1479979528000},{"_id":"themes/even/layout/mixins/container.jade","shasum":"d7907370b84077baa3c20fedc045e89851ed6ef3","modified":1479979528000},{"_id":"themes/even/layout/mixins/paginator.jade","shasum":"e46f7ec3ca4b8fee7e920bcd1f0b7eed3d040abb","modified":1479979528000},{"_id":"themes/even/layout/mixins/tags.jade","shasum":"e2ad495d0beca32cdd8dd4e7311671e479806a34","modified":1479979528000},{"_id":"themes/even/layout/page.jade","shasum":"6cc61ebc24882be9a2bd986b674b3664c189a14d","modified":1479979528000},{"_id":"themes/even/layout/partial/footer.jade","shasum":"d1a25bc156cbc707c7717eb864de65821905c4e8","modified":1479979528000},{"_id":"themes/even/layout/partial/head.jade","shasum":"79f3b83d497bc5e7e2a0ab8fdb36f3a5baf75eed","modified":1479979528000},{"_id":"themes/even/layout/partial/header.jade","shasum":"089b367937a76b44a757eed05bd3d9e428a831cc","modified":1479979528000},{"_id":"themes/even/layout/partial/layout.jade","shasum":"87057d15bb2bcd48bcf2955470d333ef55478f0a","modified":1479979528000},{"_id":"themes/even/layout/partial/meta.jade","shasum":"683ab582b3b09ec7b19a3f5f771e8d9e8c43548f","modified":1479979528000},{"_id":"themes/even/layout/partial/script.jade","shasum":"359e181905938a253f37e064c54337f3b8c2a7f9","modified":1479979528000},{"_id":"themes/even/layout/post.jade","shasum":"3d7b80616140acd5ca7d1eec4252e2c19405860b","modified":1479979528000},{"_id":"themes/even/layout/tags.jade","shasum":"0a28e85a89daaf5edf82c374402a8e15340c4cda","modified":1479979528000},{"_id":"themes/even/package.json","shasum":"2c6d808bbbb977b426e3afba61224d895eb3187e","modified":1479979528000},{"_id":"themes/even/source/css/_global.scss","shasum":"a436c48d366ba40a320b34805868bdefb836b804","modified":1479979528000},{"_id":"themes/even/source/css/_normalize.scss","shasum":"87d5cd2a60780e1796dc27deeb5337a9d48e39a8","modified":1479979528000},{"_id":"themes/even/source/css/partial/_archive.scss","shasum":"6a8848e30b92e722f9a613dfe85a7adfd0744c3c","modified":1479979528000},{"_id":"themes/even/source/css/partial/_categories.scss","shasum":"dc8a2e30791887ce4d116901c58ccea7daab7c8b","modified":1479979528000},{"_id":"themes/even/source/css/partial/_code.scss","shasum":"04e57b1660db1b9b13b48548677a39008865b336","modified":1479979528000},{"_id":"themes/even/source/css/partial/_footer.scss","shasum":"5f106eb264ee3052f8bce83476daad06cb6d969a","modified":1479979528000},{"_id":"themes/even/source/css/partial/_header.scss","shasum":"a3e534312d30109f190aaf64a4fc7af3e2269149","modified":1479979528000},{"_id":"themes/even/source/css/partial/_home.scss","shasum":"ed0e6640701a92fdc060841756a2409b6e2ea970","modified":1479979528000},{"_id":"themes/even/source/css/partial/_iconfont.scss","shasum":"737c433acfd8d7e393dfc76f17ac1689a05dbb60","modified":1479979528000},{"_id":"themes/even/source/css/partial/_media.scss","shasum":"ef20ab96d3bbb11b6f9aa20bfa0b8035d5841ab3","modified":1479979528000},{"_id":"themes/even/source/css/partial/_paginator.scss","shasum":"dd616219333a56dc37cb468148a03e8ad08f13e3","modified":1479979528000},{"_id":"themes/even/source/css/partial/_post.scss","shasum":"8b356e2043f2afbead09dca6993c17a3acd371b2","modified":1479979528000},{"_id":"themes/even/source/css/partial/_sidebar.scss","shasum":"e0967694a3ea0d8fd83e2155d3cb05306fe1e095","modified":1479979528000},{"_id":"themes/even/source/css/partial/_tags.scss","shasum":"5e7338300fe1b90187dca30bc1d37adf73466d73","modified":1479979528000},{"_id":"themes/even/source/css/style.scss","shasum":"1153e3adf149fd25c4ed06e493f58068094e1f0d","modified":1479979528000},{"_id":"themes/even/source/favicon.ico","shasum":"0505cec3b99707df7a681de37177b3cf7950cc5d","modified":1479979528000},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.eot","shasum":"fef78bd502f74fdbf0316123e176454cb3eb4e50","modified":1479979528000},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.ttf","shasum":"5e25c531901d8a9e37ab45a7f4acdbe5324b51b6","modified":1479979528000},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.woff","shasum":"95beafe485d4bdbddfecbcf3b2bc9b2d9cf5f5c5","modified":1479979528000},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.woff2","shasum":"afd0f74128f1c21c5a542b2e100870e74da663b6","modified":1479979528000},{"_id":"themes/even/source/fonts/iconfont/iconfont.eot","shasum":"73c61178be49866c64d7b891a0c5848860dc6fca","modified":1479979528000},{"_id":"themes/even/source/fonts/iconfont/iconfont.svg","shasum":"74f81a88069e6e3c3cee0f3b3c43af505487a8b1","modified":1479979528000},{"_id":"themes/even/source/fonts/iconfont/iconfont.ttf","shasum":"78f2dfb962c5fda466474122935495a4f1796b0a","modified":1479979528000},{"_id":"themes/even/source/fonts/iconfont/iconfont.woff","shasum":"ea276c35e8549c055a376fc1fd9cc47b7076fa1d","modified":1479979528000},{"_id":"themes/even/source/fonts/iconfont/iconfont.woff2","shasum":"8283d3d766398460d0121ca064ba48e6d0142613","modified":1479979528000},{"_id":"themes/even/source/js/theme.js","shasum":"1765ff4ef588127cb42e475bda9b09f54a571a7e","modified":1479979528000},{"_id":"themes/even/source/js/zepto.min.js","shasum":"d2255479efddcabfc986c2407f17cea688d008b7","modified":1479979528000},{"_id":"themes/even/source/fonts/chancery/apple-chancery-webfont.svg","shasum":"a94e508f306a742637653f98c6e8827b11d3c142","modified":1479979528000}],"Category":[{"name":"java","_id":"civw7fngu000fgm09vumhx81k"},{"name":"git","_id":"civw7fnh5000tgm09fz8tl584"},{"name":"dubbo","_id":"civw7fnh7000ygm090nt2guvz"}],"Data":[],"Page":[{"title":"tags","layout":"tags","date":"2016-11-24T09:44:35.000Z","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\nlayout: tags\ndate: 2016-11-24 17:44:35\n---\n","updated":"2016-11-24T09:44:59.000Z","path":"tags/index.html","comments":1,"_id":"civw7fngj0003gm09lnnbw9eu"},{"title":"categories","layout":"categories","date":"2016-11-24T09:43:08.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\nlayout: categories\ndate: 2016-11-24 17:43:08\n---\n","updated":"2016-11-24T09:43:52.000Z","path":"categories/index.html","comments":1,"_id":"civw7fngl0004gm09hqej8oyl"},{"title":"about","layout":"about","date":"2016-05-31T10:13:15.000Z","_content":"\n# 三唐\n\nNot exactly an about page.\n\n人生不过三万天,我要潇洒走一回。\n\n","source":"about/index.md","raw":"---\ntitle: about\nlayout: about \ndate: 2016-05-31 18:13:15\n---\n\n# 三唐\n\nNot exactly an about page.\n\n人生不过三万天,我要潇洒走一回。\n\n","updated":"2016-11-24T09:47:00.000Z","path":"about/index.html","comments":1,"_id":"civw7fngm0005gm09iw5oxnnd"}],"Post":[{"title":"Build-rest-api","date":"2016-04-27T08:41:13.000Z","_content":"\n# Why REST?\n\n1. Scalability\n1. Generality\n1. Independence\n1. Latency (Caching)\n1. Security\n1. Encapsulation\n\n# Why JSON?\n1. Ubiquity\n1. Simplicity\n1. Readability\n1. Scalability\n1. Flexibility\n\n<!-- more -->\n\n# Keep it simple\n\nRest简单理解就是对资源的管理。资源可分为基本的两类:\n1. 集合资源, `/resources`\n2. 单个资源, `/resources/123`\n\n在对资源进行命名时，不用纠结使用单数还是复数，最好始终采用复数形式，保持URL的简单和一致。\n\n# HTTP Verb\n\n这个如今到处都有讲解，我就简单说明一下。\n\n1. GET = Read\n1. PUT\n1. POST\n1. PATCH = Partially updates\n1. DELETE = Delete\n1. HEAD = Headers, no Body\n\n这几个Verbs并非与CRUD一一对应的, `^_^` . PUT和POST这两个都可以用来create和update,但他们还是有一点区别的。\n\n## PUT - Create\n\n```\nPUT /resources\n\n{\n    根据提供的数据替换现有的全部相关的资源\n}\n```\n\n## PUT - Update\n\n根据指定的ID create or update现有的资源。\n\n```\nPUT /resources/id\n\n{\n    根据id更新或者新建一个资源\n}\n```\n\n## POST - Create\n\n```\nPOST /resources\n{\n  \"desc\": \"i am gonna be created every time\"\n}\n\nResponse:\n\n201 Created\nLocation: https://api.daveztong.com/resources/123x\n\n其中123x是新建的资源ID\n```\n\n## POST - Update\n\n```\nPOST /resources/123x\n{\n  \"desc\": \"123x被当做是一个集合,并创建一个属于123x的资源\"\n}\n\nResponse:\n200 OK\n```\n\n## The difference?\n\nPUT操作是幂等的,POST非幂等。PUT的每一次操作在既定情况下都得到相同的结果,POST却是每一次都不同。\n\n\n# Best practises\n\n### 基础\n\n#### 隔离关注点\n设计时通过将请求和响应之间的不同部分隔离来让事情变得简单。保持简单的规则让我们能更关注在一些更大的更困难的问题上。\n\n请求和响应将解决一个特定的资源或集合。使用路径（path）来表明身份，body来传输内容（content）还有头信息（header）来传递元数据（metadata）。查询参数同样可以用来传递头信息的内容，但头信息是首选，因为他们更灵活、更能传达不同的信息。\n\n#### 强制使用安全连接（Secure Connections）\n\n所有的访问API行为，都需要用 TLS 通过安全连接来访问。没有必要搞清或解释什么情况需要 TLS 什么情况不需要 TLS，直接强制任何访问都要通过 TLS。\n\n理想状态下，通过拒绝所有非 TLS 请求，不响应 http 或80端口的请求以避免任何不安全的数据交换。如果现实情况中无法这样做，可以返回`403 Forbidden`响应。\n\n把非 TLS 的请求重定向(Redirect)至 TLS 连接是不明智的，这种含混/不好的客户端行为不会带来明显好处。依赖于重定向的客户端访问不仅会导致双倍的服务器负载，还会使 TLS 加密失去意义，因为在首次非 TLS 调用时，敏感信息就已经暴露出去了。\n\n#### 强制头信息 Accept 中提供版本号\n\n制定版本并在版本之间平缓过渡对于设计和维护一套API是个巨大的挑战。所以，最好在设计之初就使用一些方法来预防可能会遇到的问题。\n\n为了避免API的变动导致用户使用中产生意外结果或调用失败，__最好强制要求所有访问都需要指定版本号。请避免提供默认版本号，一旦提供，日后想要修改它会相当困难。__\n\n最适合放置版本号的位置是头信息(HTTP Headers)，在 `Accept` 段中使用自定义类型(content type)与其他元数据(metadata)一起提交。例如:\n\n```\nAccept: application/vnd.heroku+json; version=3\n```\n\n#### 支持Etag缓存\n\n在所有返回的响应中包含`ETag`头信息，用来标识资源的版本。这让用户对资源进行缓存处理成为可能，在后续的访问请求中把`If-None-Match`头信息设置为之前得到的`ETag`值，就可以侦测到已缓存的资源是否需要更新。\n\n#### 为内省而提供 Request-Id\n\n为每一个请求响应包含一个`Request-Id`头，并使用UUID作为该值。通过在客户端、服务器或任何支持服务上记录该值，它能为我们提供一种机制来跟踪、诊断和调试请求。\n\n###请求（Requests）\n\n#### 在请求的body体使用JSON格式数据\n\n在 `PUT`/`PATCH`/`POST` 请求的正文（request bodies）中使用JSON格式数据，而不是使用 form 表单形式的数据。这与我们使用JSON格式返回请求相对应，例如:\n\n```\n$ curl -X POST https://service.com/apps \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"name\": \"demoapp\"}'\n\n{\n  \"id\": \"01234567-89ab-cdef-0123-456789abcdef\",\n  \"name\": \"demoapp\",\n  \"owner\": {\n    \"email\": \"username@example.com\",\n    \"id\": \"01234567-89ab-cdef-0123-456789abcdef\"\n  },\n  ...\n}\n```\n\n#### 使用统一的资源路径格式\n\n##### 资源名（Resource names）\n\n使用复数形式为资源命名，除非这个资源在系统中是单例的 (例如，在大多数系统中，给定的用户帐户只有一个)。 这种方式保持了特定资源的统一性。\n\n##### 行为（Actions）\n\n好的末尾不需要为资源指定特殊的行为，但在特殊情况下，为某些资源指定行为却是必要的。为了描述清楚，在行为前加上一个标准的`actions`：\n\n```\n/resources/:resource/actions/:action\n```\n\n例如：\n\n```\n/tasks/{taskId}/actions/stop\n```\n\n#### 统一命名,采用camelCase或者下划线方式\n\n不管选择哪一种，只要一旦选择了就应该始终保持同一个风格。\n\n#### 最小化路径嵌套\n\n在一些有父路径/子路径嵌套关系的资源数据模块中，路径可能有非常深的嵌套关系，例如:\n\n```\n/orgs/{orgId}/apps/{appId}/dynos/{dynoId}\n```\n\n推荐在根(root)路径下指定资源来限制路径的嵌套深度。使用嵌套指定范围的资源。在上述例子中，dyno属于app，app属于org可以表示为：\n\n```\n/orgs/{orgId}\n/orgs/{orgId}/apps\n/apps/{appId}\n/apps/{appId}/dynos\n/dynos/{dynoId}\n```\n\n### 响应（Responses）\n\n#### 返回合适的状态码\n\n为每一次的响应返回合适的HTTP状态码。 好的响应应该使用如下的状态码:\n\n* `200`: `GET`请求成功，及`DELETE`或`PATCH`同步请求完成，或者`PUT`同步更新一个已存在的资源\n* `201`: `POST` 同步请求完成，或者`PUT`同步创建一个新的资源\n* `202`: `POST`，`PUT`，`DELETE`，或`PATCH`请求接收，将被异步处理\n\n使用身份认证（authentication）和授权（authorization）错误码时需要注意：\n\n* `401 Unauthorized`: 用户未认证，请求失败\n* `403 Forbidden`: 用户无权限访问该资源，请求失败\n\n当用户请求错误时，提供合适的状态码可以提供额外的信息：\n\n* `422 Unprocessable Entity`: 请求被服务器正确解析，但是包含无效字段\n* `429 Too Many Requests`: 因为访问频繁，你已经被限制访问，稍后重试\n* `500 Internal Server Error`: 服务器错误，确认状态并报告问题\n\n#### 提供全部可用的资源\n\n提供全部可显现的资源表述 (例如： 这个对象的所有属性) ，当响应码为200或是201时返回所有可用资源，包含 `PUT`/`PATCH` 和 `DELETE`\n请求，例如:\n\n\n```json\n$ curl -X DELETE \\  \n  https://service.com/apps/1f9b/domains/0fd4\n\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=utf-8\n...\n{\n  \"created_at\": \"2012-01-01T12:00:00Z\",\n  \"hostname\": \"subdomain.example.com\",\n  \"id\": \"01234567-89ab-cdef-0123-456789abcdef\",\n  \"updated_at\": \"2012-01-01T12:00:00Z\"\n}\n```\n\n当请求状态码为202时，不返回所有可用资源，例如：\n\n```\n$ curl -X DELETE \\  \n  https://service.com/apps/1f9b/dynos/05bd\n\nHTTP/1.1 202 Accepted\nContent-Type: application/json;charset=utf-8\n...\n{}\n```\n\n#### 提供资源的(UU)ID\n\n在默认情况给每一个资源一个`id`属性。除非有更好的理由，否则请使用UUID。不要使用那种在服务器上或是资源中不是全局唯一的标识，尤其是自动增长的id。\n\n生成小写的UUID格式 `8-4-4-4-12`，例如：\n\n```json\n\"id\": \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n#### 提供标准的时间戳\n\n为资源提供默认的创建时间 `createdAt` 和更新时间 `updatedAt`，例如:\n\n```json\n{\n  ...\n  \"createdAt\": 1464687808,\n  \"updatedAt\": 1464687808,\n  ...\n}\n```\n\n有些资源不需要使用时间戳那么就忽略这两个字段。\n\n#### 嵌套外键关系\n\n使用嵌套对象序列化外键关联，例如:\n\n```json\n{\n  \"name\": \"service-production\",\n  \"owner\": {\n    \"id\": \"5d8201b0...\"\n  },\n  // ...\n}\n```\n\n而不是像这样:\n\n```json\n{\n  \"name\": \"service-production\",\n  \"ownerId\": \"5d8201b0...\",\n  ...\n}\n```\n\n这种方式尽可能的把相关联的资源信息内联在一起，而不用改变资源的结构，或者引入更多的顶层字段，例如:\n\n```json\n{\n  \"name\": \"service-production\",\n  \"owner\": {\n    \"id\": \"5d8201b0...\",\n    \"name\": \"Alice\",\n    \"email\": \"alice@heroku.com\"\n  },\n  ...\n}\n```\n\n#### 生成结构化的错误\n\n响应错误的时，生成统一的、结构化的错误信息。包含一个机器可读的错误 `id`，一个人类可读的错误信息（`message`），根据情况可以添加一个`url`来告诉客户端关于这个错误的更多信息以及如何去解决它，例如:\n\n```\nHTTP/1.1 429 Too Many Requests\n```\n\n```json\n{\n  \"id\":      \"rate_limit\",\n  \"message\": \"Account reached its API rate limit.\",\n  \"url\":     \"https://docs.service.com/rate-limits\"\n}\n```\n\n文档化错误信息格式，以及客户端可能遇到的错误信息`id`。\n\n#### 显示频率限制状态\n\n客户端的访问速度限制可以维护服务器的良好状态，保证为其他客户端请求提供高性的服务。你可以使用[token bucket algorithm](http://en.wikipedia.org/wiki/Token_bucket)技术量化请求限制。\n\n为每一个带有`RateLimit-Remaining`响应头的请求，返回预留的请求tokens。\n\n#### 保证响应JSON最小化\n\n请求中多余的空格会增加响应大小，而且现在很多的HTTP客户端都会自己输出可读格式（\"prettify\"）的JSON。所以最好保证响应JSON最小化，例如：\n\n```json\n{\"beta\":false,\"email\":\"alice@heroku.com\",\"id\":\"01234567-89ab-cdef-0123-456789abcdef\",\"lastLogin\":\"2012-01-01T12:00:00Z\",\"createdAt\":\"2012-01-01T12:00:00Z\",\"updatedAt\":\"2012-01-01T12:00:00Z\"}\n```\n\n而不是这样：\n\n```json\n{\n  \"beta\": false,\n  \"email\": \"alice@heroku.com\",\n  \"id\": \"01234567-89ab-cdef-0123-456789abcdef\",\n  \"lastLogin\": \"2012-01-01T12:00:00Z\",\n  \"createdAt\": \"2012-01-01T12:00:00Z\",\n  \"updatedAt\": \"2012-01-01T12:00:00Z\"\n}\n```\n\n你可以提供可选的方式为客户端提供更详细可读的响应，使用查询参数（例如：`?pretty=true`）或者通过`Accept`头信息参数（例如：`Accept: application/vnd.heroku+json; version=3; indent=4;`）。\n\n###工件（Artifacts）\n\n\n#### 提供机器可读的JSON模式\n\n提供一个机器可读的模式来恰当的表现你的API。使用\n[prmd](https://github.com/interagent/prmd)管理你的模式，并且确保用`prmd verify`验证是有效的。\n\n#### 提供人类可读的文档\n\n提供人类可读的文档让客户端开发人员可以理解你的API。\n\n如果你用prmd创建了一个概要并且按上述要求描述，你可以为所有节点很容易的使用`prmd doc`生成Markdown文档。\n\n除了节点信息，提供一个API概述信息:\n\n* 验证授权，包含如何取得和如何使用token。\n* API稳定及版本管理，包含如何选择所需要的版本。\n* 一般情况下的请求和响应的头信息。\n* 错误的序列化格式。\n* 不同编程语言客户端使用API的例子。\n\n#### 提供可执行的例子\n\n提供可执行的示例让用户可以直接在终端里面看到API的调用情况，最大程度的让这些示例可以简单的使用，以减少用户尝试使用API的工作量。例如:\n\n```\n$ export TOKEN=... # acquire from dashboard\n$ curl -is https://$TOKEN@service.com/users\n```\n\n如果你使用[prmd](https://github.com/interagent/prmd)生成Markdown文档，每个节点都会自动获取一些示例。\n\n#### 描述稳定性\n\n描述您的API的稳定性或是它在各种各样节点环境中的完备性和稳定性，例如：加上 原型版（prototype）/开发版（development）/产品版（production）等标记。\n\n更多关于可能的稳定性和改变管理的方式，查看 [Heroku API compatibility policy](https://devcenter.heroku.com/articles/api-compatibility-policy)\n\n一旦你的API宣布产品正式版本及稳定版本时，不要在当前API版本中做一些不兼容的改变。如果你需要，请创建一个新的版本的API。\n\n# 完整的URL\nAPI里面的数据也会有URL类型的，一般来说如用户的头像、各种图片、音频等资源，都是以URL链接的形式返回的。\n\n返回的URL一定要“完整”，主要指的是不要忘记URL里面的协议部分，也就是`scheme`部分。\n","source":"_posts/Build-rest-api.md","raw":"---\ntitle: Build-rest-api\ndate: 2016-04-27 16:41:13\ntags: REST\n---\n\n# Why REST?\n\n1. Scalability\n1. Generality\n1. Independence\n1. Latency (Caching)\n1. Security\n1. Encapsulation\n\n# Why JSON?\n1. Ubiquity\n1. Simplicity\n1. Readability\n1. Scalability\n1. Flexibility\n\n<!-- more -->\n\n# Keep it simple\n\nRest简单理解就是对资源的管理。资源可分为基本的两类:\n1. 集合资源, `/resources`\n2. 单个资源, `/resources/123`\n\n在对资源进行命名时，不用纠结使用单数还是复数，最好始终采用复数形式，保持URL的简单和一致。\n\n# HTTP Verb\n\n这个如今到处都有讲解，我就简单说明一下。\n\n1. GET = Read\n1. PUT\n1. POST\n1. PATCH = Partially updates\n1. DELETE = Delete\n1. HEAD = Headers, no Body\n\n这几个Verbs并非与CRUD一一对应的, `^_^` . PUT和POST这两个都可以用来create和update,但他们还是有一点区别的。\n\n## PUT - Create\n\n```\nPUT /resources\n\n{\n    根据提供的数据替换现有的全部相关的资源\n}\n```\n\n## PUT - Update\n\n根据指定的ID create or update现有的资源。\n\n```\nPUT /resources/id\n\n{\n    根据id更新或者新建一个资源\n}\n```\n\n## POST - Create\n\n```\nPOST /resources\n{\n  \"desc\": \"i am gonna be created every time\"\n}\n\nResponse:\n\n201 Created\nLocation: https://api.daveztong.com/resources/123x\n\n其中123x是新建的资源ID\n```\n\n## POST - Update\n\n```\nPOST /resources/123x\n{\n  \"desc\": \"123x被当做是一个集合,并创建一个属于123x的资源\"\n}\n\nResponse:\n200 OK\n```\n\n## The difference?\n\nPUT操作是幂等的,POST非幂等。PUT的每一次操作在既定情况下都得到相同的结果,POST却是每一次都不同。\n\n\n# Best practises\n\n### 基础\n\n#### 隔离关注点\n设计时通过将请求和响应之间的不同部分隔离来让事情变得简单。保持简单的规则让我们能更关注在一些更大的更困难的问题上。\n\n请求和响应将解决一个特定的资源或集合。使用路径（path）来表明身份，body来传输内容（content）还有头信息（header）来传递元数据（metadata）。查询参数同样可以用来传递头信息的内容，但头信息是首选，因为他们更灵活、更能传达不同的信息。\n\n#### 强制使用安全连接（Secure Connections）\n\n所有的访问API行为，都需要用 TLS 通过安全连接来访问。没有必要搞清或解释什么情况需要 TLS 什么情况不需要 TLS，直接强制任何访问都要通过 TLS。\n\n理想状态下，通过拒绝所有非 TLS 请求，不响应 http 或80端口的请求以避免任何不安全的数据交换。如果现实情况中无法这样做，可以返回`403 Forbidden`响应。\n\n把非 TLS 的请求重定向(Redirect)至 TLS 连接是不明智的，这种含混/不好的客户端行为不会带来明显好处。依赖于重定向的客户端访问不仅会导致双倍的服务器负载，还会使 TLS 加密失去意义，因为在首次非 TLS 调用时，敏感信息就已经暴露出去了。\n\n#### 强制头信息 Accept 中提供版本号\n\n制定版本并在版本之间平缓过渡对于设计和维护一套API是个巨大的挑战。所以，最好在设计之初就使用一些方法来预防可能会遇到的问题。\n\n为了避免API的变动导致用户使用中产生意外结果或调用失败，__最好强制要求所有访问都需要指定版本号。请避免提供默认版本号，一旦提供，日后想要修改它会相当困难。__\n\n最适合放置版本号的位置是头信息(HTTP Headers)，在 `Accept` 段中使用自定义类型(content type)与其他元数据(metadata)一起提交。例如:\n\n```\nAccept: application/vnd.heroku+json; version=3\n```\n\n#### 支持Etag缓存\n\n在所有返回的响应中包含`ETag`头信息，用来标识资源的版本。这让用户对资源进行缓存处理成为可能，在后续的访问请求中把`If-None-Match`头信息设置为之前得到的`ETag`值，就可以侦测到已缓存的资源是否需要更新。\n\n#### 为内省而提供 Request-Id\n\n为每一个请求响应包含一个`Request-Id`头，并使用UUID作为该值。通过在客户端、服务器或任何支持服务上记录该值，它能为我们提供一种机制来跟踪、诊断和调试请求。\n\n###请求（Requests）\n\n#### 在请求的body体使用JSON格式数据\n\n在 `PUT`/`PATCH`/`POST` 请求的正文（request bodies）中使用JSON格式数据，而不是使用 form 表单形式的数据。这与我们使用JSON格式返回请求相对应，例如:\n\n```\n$ curl -X POST https://service.com/apps \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"name\": \"demoapp\"}'\n\n{\n  \"id\": \"01234567-89ab-cdef-0123-456789abcdef\",\n  \"name\": \"demoapp\",\n  \"owner\": {\n    \"email\": \"username@example.com\",\n    \"id\": \"01234567-89ab-cdef-0123-456789abcdef\"\n  },\n  ...\n}\n```\n\n#### 使用统一的资源路径格式\n\n##### 资源名（Resource names）\n\n使用复数形式为资源命名，除非这个资源在系统中是单例的 (例如，在大多数系统中，给定的用户帐户只有一个)。 这种方式保持了特定资源的统一性。\n\n##### 行为（Actions）\n\n好的末尾不需要为资源指定特殊的行为，但在特殊情况下，为某些资源指定行为却是必要的。为了描述清楚，在行为前加上一个标准的`actions`：\n\n```\n/resources/:resource/actions/:action\n```\n\n例如：\n\n```\n/tasks/{taskId}/actions/stop\n```\n\n#### 统一命名,采用camelCase或者下划线方式\n\n不管选择哪一种，只要一旦选择了就应该始终保持同一个风格。\n\n#### 最小化路径嵌套\n\n在一些有父路径/子路径嵌套关系的资源数据模块中，路径可能有非常深的嵌套关系，例如:\n\n```\n/orgs/{orgId}/apps/{appId}/dynos/{dynoId}\n```\n\n推荐在根(root)路径下指定资源来限制路径的嵌套深度。使用嵌套指定范围的资源。在上述例子中，dyno属于app，app属于org可以表示为：\n\n```\n/orgs/{orgId}\n/orgs/{orgId}/apps\n/apps/{appId}\n/apps/{appId}/dynos\n/dynos/{dynoId}\n```\n\n### 响应（Responses）\n\n#### 返回合适的状态码\n\n为每一次的响应返回合适的HTTP状态码。 好的响应应该使用如下的状态码:\n\n* `200`: `GET`请求成功，及`DELETE`或`PATCH`同步请求完成，或者`PUT`同步更新一个已存在的资源\n* `201`: `POST` 同步请求完成，或者`PUT`同步创建一个新的资源\n* `202`: `POST`，`PUT`，`DELETE`，或`PATCH`请求接收，将被异步处理\n\n使用身份认证（authentication）和授权（authorization）错误码时需要注意：\n\n* `401 Unauthorized`: 用户未认证，请求失败\n* `403 Forbidden`: 用户无权限访问该资源，请求失败\n\n当用户请求错误时，提供合适的状态码可以提供额外的信息：\n\n* `422 Unprocessable Entity`: 请求被服务器正确解析，但是包含无效字段\n* `429 Too Many Requests`: 因为访问频繁，你已经被限制访问，稍后重试\n* `500 Internal Server Error`: 服务器错误，确认状态并报告问题\n\n#### 提供全部可用的资源\n\n提供全部可显现的资源表述 (例如： 这个对象的所有属性) ，当响应码为200或是201时返回所有可用资源，包含 `PUT`/`PATCH` 和 `DELETE`\n请求，例如:\n\n\n```json\n$ curl -X DELETE \\  \n  https://service.com/apps/1f9b/domains/0fd4\n\nHTTP/1.1 200 OK\nContent-Type: application/json;charset=utf-8\n...\n{\n  \"created_at\": \"2012-01-01T12:00:00Z\",\n  \"hostname\": \"subdomain.example.com\",\n  \"id\": \"01234567-89ab-cdef-0123-456789abcdef\",\n  \"updated_at\": \"2012-01-01T12:00:00Z\"\n}\n```\n\n当请求状态码为202时，不返回所有可用资源，例如：\n\n```\n$ curl -X DELETE \\  \n  https://service.com/apps/1f9b/dynos/05bd\n\nHTTP/1.1 202 Accepted\nContent-Type: application/json;charset=utf-8\n...\n{}\n```\n\n#### 提供资源的(UU)ID\n\n在默认情况给每一个资源一个`id`属性。除非有更好的理由，否则请使用UUID。不要使用那种在服务器上或是资源中不是全局唯一的标识，尤其是自动增长的id。\n\n生成小写的UUID格式 `8-4-4-4-12`，例如：\n\n```json\n\"id\": \"01234567-89ab-cdef-0123-456789abcdef\"\n```\n\n#### 提供标准的时间戳\n\n为资源提供默认的创建时间 `createdAt` 和更新时间 `updatedAt`，例如:\n\n```json\n{\n  ...\n  \"createdAt\": 1464687808,\n  \"updatedAt\": 1464687808,\n  ...\n}\n```\n\n有些资源不需要使用时间戳那么就忽略这两个字段。\n\n#### 嵌套外键关系\n\n使用嵌套对象序列化外键关联，例如:\n\n```json\n{\n  \"name\": \"service-production\",\n  \"owner\": {\n    \"id\": \"5d8201b0...\"\n  },\n  // ...\n}\n```\n\n而不是像这样:\n\n```json\n{\n  \"name\": \"service-production\",\n  \"ownerId\": \"5d8201b0...\",\n  ...\n}\n```\n\n这种方式尽可能的把相关联的资源信息内联在一起，而不用改变资源的结构，或者引入更多的顶层字段，例如:\n\n```json\n{\n  \"name\": \"service-production\",\n  \"owner\": {\n    \"id\": \"5d8201b0...\",\n    \"name\": \"Alice\",\n    \"email\": \"alice@heroku.com\"\n  },\n  ...\n}\n```\n\n#### 生成结构化的错误\n\n响应错误的时，生成统一的、结构化的错误信息。包含一个机器可读的错误 `id`，一个人类可读的错误信息（`message`），根据情况可以添加一个`url`来告诉客户端关于这个错误的更多信息以及如何去解决它，例如:\n\n```\nHTTP/1.1 429 Too Many Requests\n```\n\n```json\n{\n  \"id\":      \"rate_limit\",\n  \"message\": \"Account reached its API rate limit.\",\n  \"url\":     \"https://docs.service.com/rate-limits\"\n}\n```\n\n文档化错误信息格式，以及客户端可能遇到的错误信息`id`。\n\n#### 显示频率限制状态\n\n客户端的访问速度限制可以维护服务器的良好状态，保证为其他客户端请求提供高性的服务。你可以使用[token bucket algorithm](http://en.wikipedia.org/wiki/Token_bucket)技术量化请求限制。\n\n为每一个带有`RateLimit-Remaining`响应头的请求，返回预留的请求tokens。\n\n#### 保证响应JSON最小化\n\n请求中多余的空格会增加响应大小，而且现在很多的HTTP客户端都会自己输出可读格式（\"prettify\"）的JSON。所以最好保证响应JSON最小化，例如：\n\n```json\n{\"beta\":false,\"email\":\"alice@heroku.com\",\"id\":\"01234567-89ab-cdef-0123-456789abcdef\",\"lastLogin\":\"2012-01-01T12:00:00Z\",\"createdAt\":\"2012-01-01T12:00:00Z\",\"updatedAt\":\"2012-01-01T12:00:00Z\"}\n```\n\n而不是这样：\n\n```json\n{\n  \"beta\": false,\n  \"email\": \"alice@heroku.com\",\n  \"id\": \"01234567-89ab-cdef-0123-456789abcdef\",\n  \"lastLogin\": \"2012-01-01T12:00:00Z\",\n  \"createdAt\": \"2012-01-01T12:00:00Z\",\n  \"updatedAt\": \"2012-01-01T12:00:00Z\"\n}\n```\n\n你可以提供可选的方式为客户端提供更详细可读的响应，使用查询参数（例如：`?pretty=true`）或者通过`Accept`头信息参数（例如：`Accept: application/vnd.heroku+json; version=3; indent=4;`）。\n\n###工件（Artifacts）\n\n\n#### 提供机器可读的JSON模式\n\n提供一个机器可读的模式来恰当的表现你的API。使用\n[prmd](https://github.com/interagent/prmd)管理你的模式，并且确保用`prmd verify`验证是有效的。\n\n#### 提供人类可读的文档\n\n提供人类可读的文档让客户端开发人员可以理解你的API。\n\n如果你用prmd创建了一个概要并且按上述要求描述，你可以为所有节点很容易的使用`prmd doc`生成Markdown文档。\n\n除了节点信息，提供一个API概述信息:\n\n* 验证授权，包含如何取得和如何使用token。\n* API稳定及版本管理，包含如何选择所需要的版本。\n* 一般情况下的请求和响应的头信息。\n* 错误的序列化格式。\n* 不同编程语言客户端使用API的例子。\n\n#### 提供可执行的例子\n\n提供可执行的示例让用户可以直接在终端里面看到API的调用情况，最大程度的让这些示例可以简单的使用，以减少用户尝试使用API的工作量。例如:\n\n```\n$ export TOKEN=... # acquire from dashboard\n$ curl -is https://$TOKEN@service.com/users\n```\n\n如果你使用[prmd](https://github.com/interagent/prmd)生成Markdown文档，每个节点都会自动获取一些示例。\n\n#### 描述稳定性\n\n描述您的API的稳定性或是它在各种各样节点环境中的完备性和稳定性，例如：加上 原型版（prototype）/开发版（development）/产品版（production）等标记。\n\n更多关于可能的稳定性和改变管理的方式，查看 [Heroku API compatibility policy](https://devcenter.heroku.com/articles/api-compatibility-policy)\n\n一旦你的API宣布产品正式版本及稳定版本时，不要在当前API版本中做一些不兼容的改变。如果你需要，请创建一个新的版本的API。\n\n# 完整的URL\nAPI里面的数据也会有URL类型的，一般来说如用户的头像、各种图片、音频等资源，都是以URL链接的形式返回的。\n\n返回的URL一定要“完整”，主要指的是不要忘记URL里面的协议部分，也就是`scheme`部分。\n","slug":"Build-rest-api","published":1,"updated":"2016-11-24T09:51:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fng60000gm0923ha6x56"},{"title":"深入理解HashMap","date":"2016-06-27T09:12:53.000Z","_content":"\n对于一个Java开发者来说，最常用的Map结构莫过于HashMap。但我发现很多人对其内部是如何进行存储和查找的基本没什么概念或者有点概念但却是错误的或不全面的，对于靠这个吃饭的人来说，如果你不了解他，你怎么能放心的把你的数据交给他呢，这就好比把自己的饭碗交给了一个不认识的人，that's terrible! 所以本文就带你深入理解一下HashMap, 内容大致涵盖如下几个方面:\n\n1. 比较HashMap在java7和java8中的不同点\n2. 性能\n4. 可能的问题\n\n# 存储\nHashMap实现了`Map<K,V>`，所以包含了以下几个主要的方法:\n```\nV put(K key, V value)\nV get(Object key)\nV remove(Object key)\nBoolean containsKey(Object key)\n```\n\n<!-- more -->\n\nHashMap使用`Entry<K, V>`作为内部存储值的结构,基本结构:\n```\nstatic class Entry<K,V> implements Map.Entry<K,V> {\n    final K key; // 键值\n    V value;// 实际值\n    Entry<K,V> next; // 下一条记录，构成一个单向链表\n    int hash;// key的hash值，出于性能上的考虑，这个值主要是为了避免重复计算hash值\n}\n```\n\nHashMap将数据存储在多个单向链表里面，这个单向链表通常叫做bucket，使用一个Entry<K,V>[]array来存储这些bucket. 这个array的默认大小为16.\n\n```\n/**\n  * The default initial capacity - MUST be a power of two.\n  */\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n```\n\n这张示意图可以大致表示HashMap是怎么存的数据:\n\n![图例](http://ww4.sinaimg.cn/mw690/50508d62gw1f59y3ncsu4j20ta0ji0ty.jpg)\n\n`bucket array`的大小为n,i<sub>0</sub> 存储了3个entry构成的singly linked list,i<sub>1</sub>存了个null,i<sub>n-1</sub>只存了1个entry。\n\n当调用put(K key, V value)或者get(Object key)时,就会根据key值计算相应的bucket在array中的index，然后进行添加或者获取Entry.\n\n## 索引的计算方式\n\n```\n// java7\nfinal int hash(Object k) {\n    int h = hashSeed;\n    if (0 != h && k instanceof String) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h >>> 20) ^ (h >>> 12);\n    return h ^ (h >>> 7) ^ (h >>> 4);\n}\n\n// java8\n/**\n + Computes key.hashCode() and spreads (XORs) higher bits of hash\n + to lower.  Because the table uses power-of-two masking, sets of\n + hashes that vary only in bits above the current mask will\n + always collide. (Among known examples are sets of Float keys\n + holding consecutive whole numbers in small tables.)  So we\n + apply a transform that spreads the impact of higher bits\n + downward. There is a tradeoff between speed, utility, and\n + quality of bit-spreading. Because many common sets of hashes\n + are already reasonably distributed (so don't benefit from\n + spreading), and because we use trees to handle large sets of\n + collisions in bins, we just XOR some shifted bits in the\n + cheapest possible way to reduce systematic lossage, as well as\n + to incorporate impact of the highest bits that would otherwise\n + never be used in index calculations because of table bounds.\n */\nstatic final int hash(Object key) {\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n\n/**\n * Returns index for hash code h.\n */\nstatic int indexFor(int h, int length) {\n    // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\";\n    return h & (length-1);\n}\n```\n\n为了高效的存取数据，bucket array的长度必须为2的指数次方，从上面默认大小16的注释上可以看到，接下来就解释一下为什么这个是必须的。\n\n假设默认bucket array的默认大小是17，index即为h&(17-1),16的二进制表示为00010000，此时无论h的是什么，h&(17-1)的值只可能是16或者0，所以bucket array只有bucket 16和bucket 0能够被用到，其他都浪费了。但是如果bucket array的大小为2的指数次方，如默认大小2<sup>4</sup>，h&15的结果值为0-15，每个bucket都被使用了，不存在浪费情况。\n\n由此可以看出bucket array的大小为2<sup>n</sup>是很重要的，当你指定一个非2<sup>n</sup>得大小时，HashMap采取的策略是向上取下一个2的指数次方。\n\n# 自动扩展\n\n在获取到bucket的index之后，就可以遍历bucket中的linked list了。设想我们的bucket中存储了大量数据，遍历linked list的时候就可能会产生性能问题。所以HashMap在发现自己存储的数据量超过某个阀值的时候就会自动对bucket array升级，即扩容。\n\nHashMap提供了一个可指定初始容量和loadFactor的构造器:\n```\npublic HashMap(int initialCapacity, float loadFactor)\n```\n\n默认的`initialCapacity`为16，`loadFactor`为0.75.\n\n每次调用put()时都会执行检查是否需要扩容，当`map.size>(threshold=capacity*loadFactor)`bucket array的大小会扩展至原来的2倍,bucket的数量也增加了，所以随即发生的就是重新分布所有的元素。问题来了，为什么要这么做呢？扩展array bucket的主要目的就是减小bucket中的linked list的大小，这样才能快速的在其上进行CRUD操作。 在元素的重新分布之后，有相同hash值的存在同一个bucket中，之前在同一个bucket中但是hash值不一样的元素可能分配之后就不在同一个bucket中了。\n\n过程如下图:\n\n![初始结构](http://ww2.sinaimg.cn/mw690/50508d62gw1f59y3lvrypj20q20lo75b.jpg)\n![扩展后的结构](http://ww3.sinaimg.cn/mw690/50508d62gw1f59y3mj4myj20y80cwgmt.jpg)\n\n__HashMap虽然提供了扩容的机制，但没有提供相应的缩容机制。__\n\n# 线程安全\n\n大家都知道HashMap是非线程安全的，但深究过为什么麽？ 考虑如果一个写线程和一个读线程同时操作一个HashMap，写的时候如果发生扩容，那么读的时候就可能出现失败的现象，因为索引和list结构都变了。\n\nHashMap的小伙伴HashTable的实现是线程安全的，因为其CRUD都做了同步操作，性能自然是不能同HashMap相比，除非在特殊场景，否则不推荐使用。\n\n# key值可变性\n通常我们可能会看到有人说最好是使用String and Integer作为Map的key值，但是为什么呢？ 主要原因是因为其`immutable`的特性。如果使用自己定义的对象作为key,请确保其hash不可变，否则可能丢失之前存储的数据。\n\n# Java8的变化\n\n从代码量上来看就知道java8做了一些改进，java7的HashMap只有1000行左右的代码，java8却用了2000多行。\nJava8新增了一个Node对象，结构和Entry是一样的:\n```\nstatic class Node<K,V> implements Map.Entry<K,V> {\n    final int hash;\n    final K key;\n    V value;\n    Node<K,V> next;\n}\n```\nbucket中存储的是这个新的Node对象。与Java7不同的地方是，Node可以扩展为TreeNode,TreeNode的实现是一个红黑树，这样增删等操作可以降到`O(log(n))`的级别。\n\nTreeNode部分代码\n```\nstatic final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {\n    TreeNode<K,V> parent;  // red-black tree links\n    TreeNode<K,V> left;\n    TreeNode<K,V> right;\n    TreeNode<K,V> prev;    // needed to unlink next upon deletion\n    boolean red;\n    TreeNode(int hash, K key, V val, Node<K,V> next) {\n        super(hash, key, val, next);\n    }\n\n    /**\n     + Returns root of tree containing this node.\n     */\n    final TreeNode<K,V> root() {\n        for (TreeNode<K,V> r = this, p;;) {\n            if ((p = r.parent) == null)\n                return r;\n            r = p;\n        }\n    }\n}\n```\n\n使用红黑树的一个主要好处就是当某个bucket中存在很多元素时，查找的时间为`O(log(n)) `,而原来的为`O(n)`。\n\n还有一点值得注意的是bucket中既可存放linked list,也可以存放TreeNode. 何时使用哪种结构取决于bucket中的元素个数。源码中定义了一个阀值:\n\n```\n/**\n + The bin count threshold for using a tree rather than list for a\n + bin.  Bins are converted to trees when adding an element to a\n + bin with at least this many nodes. The value must be greater\n + than 2 and should be at least 8 to mesh with assumptions in\n + tree removal about conversion back to plain bins upon\n + shrinkage.\n */\nstatic final int TREEIFY_THRESHOLD = 8;\n```\n\n超过8个就转换成TreeNode，否则就使用Linked List.\n\n# 性能问题\n\nHashMap性能是否过关，主要取决于hash function的设计是否合理。 hash function如果设计不合理，bucket array就不能够被充分利用，假设有`n(n>=16)`个元素，bucket array长度为L,bucket<sub>i</sub>存储`k(k<n/2)`个元素,另一个bucket<sub>j</sub>存储n-k个,如果是使用java7，查找最坏情况需要`O(n-k)`, 但如果均匀分布的话,java7就只需要`O(n/L)`.\n\n之前说推荐使用String or Integer作为Key就是因为其有不错的hash function。\n\n# 自动扩展的开销\n\n前面已经讲过，当put()的时候达到临界值时就会对bucket array进行扩容，每次扩容都是一个开销很大的过程，如果提前知道自己需要多大的容量，推荐在创建HashMap的时候就设置好initialCapacity and loadFactor.\n\n# 结语\n\n对于日常开发来说，上述各方面可能会让你觉得没太大用处，但对于一个认真的开发者来说，我们不能仅仅做到知其然，更要做到知其所以然，这样我们才能好的利用这些工具为我们解决问题，并且在出现问题的时候能够快速定位和得出解决问题的方案。That is what makes you different!\n\n\n\n\n\n","source":"_posts/深入理解HashMap.md","raw":"---\ntitle: 深入理解HashMap\ndate: 2016-06-27 17:12:53\ntags: [java,HashMap]\n---\n\n对于一个Java开发者来说，最常用的Map结构莫过于HashMap。但我发现很多人对其内部是如何进行存储和查找的基本没什么概念或者有点概念但却是错误的或不全面的，对于靠这个吃饭的人来说，如果你不了解他，你怎么能放心的把你的数据交给他呢，这就好比把自己的饭碗交给了一个不认识的人，that's terrible! 所以本文就带你深入理解一下HashMap, 内容大致涵盖如下几个方面:\n\n1. 比较HashMap在java7和java8中的不同点\n2. 性能\n4. 可能的问题\n\n# 存储\nHashMap实现了`Map<K,V>`，所以包含了以下几个主要的方法:\n```\nV put(K key, V value)\nV get(Object key)\nV remove(Object key)\nBoolean containsKey(Object key)\n```\n\n<!-- more -->\n\nHashMap使用`Entry<K, V>`作为内部存储值的结构,基本结构:\n```\nstatic class Entry<K,V> implements Map.Entry<K,V> {\n    final K key; // 键值\n    V value;// 实际值\n    Entry<K,V> next; // 下一条记录，构成一个单向链表\n    int hash;// key的hash值，出于性能上的考虑，这个值主要是为了避免重复计算hash值\n}\n```\n\nHashMap将数据存储在多个单向链表里面，这个单向链表通常叫做bucket，使用一个Entry<K,V>[]array来存储这些bucket. 这个array的默认大小为16.\n\n```\n/**\n  * The default initial capacity - MUST be a power of two.\n  */\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n```\n\n这张示意图可以大致表示HashMap是怎么存的数据:\n\n![图例](http://ww4.sinaimg.cn/mw690/50508d62gw1f59y3ncsu4j20ta0ji0ty.jpg)\n\n`bucket array`的大小为n,i<sub>0</sub> 存储了3个entry构成的singly linked list,i<sub>1</sub>存了个null,i<sub>n-1</sub>只存了1个entry。\n\n当调用put(K key, V value)或者get(Object key)时,就会根据key值计算相应的bucket在array中的index，然后进行添加或者获取Entry.\n\n## 索引的计算方式\n\n```\n// java7\nfinal int hash(Object k) {\n    int h = hashSeed;\n    if (0 != h && k instanceof String) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h >>> 20) ^ (h >>> 12);\n    return h ^ (h >>> 7) ^ (h >>> 4);\n}\n\n// java8\n/**\n + Computes key.hashCode() and spreads (XORs) higher bits of hash\n + to lower.  Because the table uses power-of-two masking, sets of\n + hashes that vary only in bits above the current mask will\n + always collide. (Among known examples are sets of Float keys\n + holding consecutive whole numbers in small tables.)  So we\n + apply a transform that spreads the impact of higher bits\n + downward. There is a tradeoff between speed, utility, and\n + quality of bit-spreading. Because many common sets of hashes\n + are already reasonably distributed (so don't benefit from\n + spreading), and because we use trees to handle large sets of\n + collisions in bins, we just XOR some shifted bits in the\n + cheapest possible way to reduce systematic lossage, as well as\n + to incorporate impact of the highest bits that would otherwise\n + never be used in index calculations because of table bounds.\n */\nstatic final int hash(Object key) {\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n\n/**\n * Returns index for hash code h.\n */\nstatic int indexFor(int h, int length) {\n    // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\";\n    return h & (length-1);\n}\n```\n\n为了高效的存取数据，bucket array的长度必须为2的指数次方，从上面默认大小16的注释上可以看到，接下来就解释一下为什么这个是必须的。\n\n假设默认bucket array的默认大小是17，index即为h&(17-1),16的二进制表示为00010000，此时无论h的是什么，h&(17-1)的值只可能是16或者0，所以bucket array只有bucket 16和bucket 0能够被用到，其他都浪费了。但是如果bucket array的大小为2的指数次方，如默认大小2<sup>4</sup>，h&15的结果值为0-15，每个bucket都被使用了，不存在浪费情况。\n\n由此可以看出bucket array的大小为2<sup>n</sup>是很重要的，当你指定一个非2<sup>n</sup>得大小时，HashMap采取的策略是向上取下一个2的指数次方。\n\n# 自动扩展\n\n在获取到bucket的index之后，就可以遍历bucket中的linked list了。设想我们的bucket中存储了大量数据，遍历linked list的时候就可能会产生性能问题。所以HashMap在发现自己存储的数据量超过某个阀值的时候就会自动对bucket array升级，即扩容。\n\nHashMap提供了一个可指定初始容量和loadFactor的构造器:\n```\npublic HashMap(int initialCapacity, float loadFactor)\n```\n\n默认的`initialCapacity`为16，`loadFactor`为0.75.\n\n每次调用put()时都会执行检查是否需要扩容，当`map.size>(threshold=capacity*loadFactor)`bucket array的大小会扩展至原来的2倍,bucket的数量也增加了，所以随即发生的就是重新分布所有的元素。问题来了，为什么要这么做呢？扩展array bucket的主要目的就是减小bucket中的linked list的大小，这样才能快速的在其上进行CRUD操作。 在元素的重新分布之后，有相同hash值的存在同一个bucket中，之前在同一个bucket中但是hash值不一样的元素可能分配之后就不在同一个bucket中了。\n\n过程如下图:\n\n![初始结构](http://ww2.sinaimg.cn/mw690/50508d62gw1f59y3lvrypj20q20lo75b.jpg)\n![扩展后的结构](http://ww3.sinaimg.cn/mw690/50508d62gw1f59y3mj4myj20y80cwgmt.jpg)\n\n__HashMap虽然提供了扩容的机制，但没有提供相应的缩容机制。__\n\n# 线程安全\n\n大家都知道HashMap是非线程安全的，但深究过为什么麽？ 考虑如果一个写线程和一个读线程同时操作一个HashMap，写的时候如果发生扩容，那么读的时候就可能出现失败的现象，因为索引和list结构都变了。\n\nHashMap的小伙伴HashTable的实现是线程安全的，因为其CRUD都做了同步操作，性能自然是不能同HashMap相比，除非在特殊场景，否则不推荐使用。\n\n# key值可变性\n通常我们可能会看到有人说最好是使用String and Integer作为Map的key值，但是为什么呢？ 主要原因是因为其`immutable`的特性。如果使用自己定义的对象作为key,请确保其hash不可变，否则可能丢失之前存储的数据。\n\n# Java8的变化\n\n从代码量上来看就知道java8做了一些改进，java7的HashMap只有1000行左右的代码，java8却用了2000多行。\nJava8新增了一个Node对象，结构和Entry是一样的:\n```\nstatic class Node<K,V> implements Map.Entry<K,V> {\n    final int hash;\n    final K key;\n    V value;\n    Node<K,V> next;\n}\n```\nbucket中存储的是这个新的Node对象。与Java7不同的地方是，Node可以扩展为TreeNode,TreeNode的实现是一个红黑树，这样增删等操作可以降到`O(log(n))`的级别。\n\nTreeNode部分代码\n```\nstatic final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {\n    TreeNode<K,V> parent;  // red-black tree links\n    TreeNode<K,V> left;\n    TreeNode<K,V> right;\n    TreeNode<K,V> prev;    // needed to unlink next upon deletion\n    boolean red;\n    TreeNode(int hash, K key, V val, Node<K,V> next) {\n        super(hash, key, val, next);\n    }\n\n    /**\n     + Returns root of tree containing this node.\n     */\n    final TreeNode<K,V> root() {\n        for (TreeNode<K,V> r = this, p;;) {\n            if ((p = r.parent) == null)\n                return r;\n            r = p;\n        }\n    }\n}\n```\n\n使用红黑树的一个主要好处就是当某个bucket中存在很多元素时，查找的时间为`O(log(n)) `,而原来的为`O(n)`。\n\n还有一点值得注意的是bucket中既可存放linked list,也可以存放TreeNode. 何时使用哪种结构取决于bucket中的元素个数。源码中定义了一个阀值:\n\n```\n/**\n + The bin count threshold for using a tree rather than list for a\n + bin.  Bins are converted to trees when adding an element to a\n + bin with at least this many nodes. The value must be greater\n + than 2 and should be at least 8 to mesh with assumptions in\n + tree removal about conversion back to plain bins upon\n + shrinkage.\n */\nstatic final int TREEIFY_THRESHOLD = 8;\n```\n\n超过8个就转换成TreeNode，否则就使用Linked List.\n\n# 性能问题\n\nHashMap性能是否过关，主要取决于hash function的设计是否合理。 hash function如果设计不合理，bucket array就不能够被充分利用，假设有`n(n>=16)`个元素，bucket array长度为L,bucket<sub>i</sub>存储`k(k<n/2)`个元素,另一个bucket<sub>j</sub>存储n-k个,如果是使用java7，查找最坏情况需要`O(n-k)`, 但如果均匀分布的话,java7就只需要`O(n/L)`.\n\n之前说推荐使用String or Integer作为Key就是因为其有不错的hash function。\n\n# 自动扩展的开销\n\n前面已经讲过，当put()的时候达到临界值时就会对bucket array进行扩容，每次扩容都是一个开销很大的过程，如果提前知道自己需要多大的容量，推荐在创建HashMap的时候就设置好initialCapacity and loadFactor.\n\n# 结语\n\n对于日常开发来说，上述各方面可能会让你觉得没太大用处，但对于一个认真的开发者来说，我们不能仅仅做到知其然，更要做到知其所以然，这样我们才能好的利用这些工具为我们解决问题，并且在出现问题的时候能够快速定位和得出解决问题的方案。That is what makes you different!\n\n\n\n\n\n","slug":"深入理解HashMap","published":1,"updated":"2016-11-24T09:52:43.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fngo0006gm09om5rmwod"},{"title":"how-to-create-products-customers-love","date":"2016-05-14T15:11:20.000Z","_content":"\n# My Opinion\n一个不错的开发者有很大的潜力能成为一个不错的PM。PM这里不仅仅指product manager but also means project manager. 出于对PM的兴趣，近期在尝试看一些PM相关的书，总结了一些Keynote供后续回顾。\n\n# 产品管理&项目管理\n\n* 产品管理更多是探索定义产品功能，验证产品可行可用性，发现产品价值。 协调交互设计，视觉设计，原型设计进度与流程。产品在设计每个周期开发功能的时候尽量留出20%的时间供开发人员优化代码和修复可能的问题。(this is called headroom)\n* 项目管理控制项目进度，合理分配资源，解决项目过程中出现的各种问题，保证项目按时按质交付。\n\n<!-- more -->\n\n# 寻找合适的产品经理\n公司内部其他岗位上的人员，开发人员，设计人员等都可能是很好的产品经理备选人员，等待发掘。\n## 优秀产品经理的素质\n1. 对产品的热情\n1. 用户立场\n1. 判断力和决策力\n1. 职业操守\n1. 信心\n1. 态度\n1. 技能\n1. 注意力\n1. 时间管理\n1. 沟通技能\n1. 商业技能\nPM通常需要与上级其他部门沟通，为了使沟通有效需要熟悉他们常说的概念和术语。如成功构成，边际效应，市场份额，产品定位和品牌等。所以需要一定的商业技能。\n\n# 管理产品经理\n这份工作通常由产品总监来完成。主要有两方面的职责:\n1. 组建优秀的产品团队。\n1. 规划产品全局战略，对产品组合负责。\n\n## 建设产品团队\n\n简单来说，发现适合做产品管理的人员，同时找出不适合的人员。发现有做产品潜质的人员时，应尽量给予其足够的时间和信任并监督和指导其不断进步，这样不仅提高了手下的能力，也是对自己能力的一种扩大，手下产品做得好也就是自己产品做得好。有些人天生就不合适做产品，所以需要及时发现以免浪费研发的时间和失去用户对产品的信任。\n\n## 规划公司的产品战略\n\n结合公司的商业战略规划产品战略，做到商业与用户需求的完美结合。同时需要解决不同产品经理提出的方案的冲突，做好整体产品的组合和规划。\n\n# 巴顿将军的忠告\n## 目标管理\n在构思一个产品功能且未形成最终方案的时候，应该充分发挥视觉设计，交互设计师的个人创造力，应该告诉他们接下来要做什么，而不是告诉他们如何做。让他们根据自己对市场的理解和对用户的调研来发挥想象。\n\n# 评估产品机会\n评估产品机会是产品经理的重要职责，通过评估产品机会可以淘汰bad idea,避免资源浪费。尤其对于资源有限的创业公司而言。\n\n为了评估产品机会，可以要求产品经理回答以下几个问题:\n1. 产品要解决什么问题?(产品价值)\n1. 为谁解决这个问题?(目标市场)\n1. 成功的机会有多大?(市场规模)\n1. 怎样判断产品成功与否?(度量指标或收益指标)\n1. 有哪些同类产品?(竞品分析)\n1. 为什么我们最适合做这个产品?(竞争优势)\n1. 时机是否合适?(市场时机)\n1. 如何把产品推向市场?(营销组合策略)\n1. 成功的必要条件是什么?(解决方案要满足的条件) \n1. 根据以上问题，得出评估结论?(继续或放弃)\n\n评估产品机会的时候不应该与具体解决方案一起讨论，否则容易造成具体方案遇到困难时就直接把产品机会一起否定掉。\n\n\n","source":"_posts/how-to-create-products-customers-love.md","raw":"---\ntitle: how-to-create-products-customers-love\ndate: 2016-05-14 23:11:20\ntags: PM\n---\n\n# My Opinion\n一个不错的开发者有很大的潜力能成为一个不错的PM。PM这里不仅仅指product manager but also means project manager. 出于对PM的兴趣，近期在尝试看一些PM相关的书，总结了一些Keynote供后续回顾。\n\n# 产品管理&项目管理\n\n* 产品管理更多是探索定义产品功能，验证产品可行可用性，发现产品价值。 协调交互设计，视觉设计，原型设计进度与流程。产品在设计每个周期开发功能的时候尽量留出20%的时间供开发人员优化代码和修复可能的问题。(this is called headroom)\n* 项目管理控制项目进度，合理分配资源，解决项目过程中出现的各种问题，保证项目按时按质交付。\n\n<!-- more -->\n\n# 寻找合适的产品经理\n公司内部其他岗位上的人员，开发人员，设计人员等都可能是很好的产品经理备选人员，等待发掘。\n## 优秀产品经理的素质\n1. 对产品的热情\n1. 用户立场\n1. 判断力和决策力\n1. 职业操守\n1. 信心\n1. 态度\n1. 技能\n1. 注意力\n1. 时间管理\n1. 沟通技能\n1. 商业技能\nPM通常需要与上级其他部门沟通，为了使沟通有效需要熟悉他们常说的概念和术语。如成功构成，边际效应，市场份额，产品定位和品牌等。所以需要一定的商业技能。\n\n# 管理产品经理\n这份工作通常由产品总监来完成。主要有两方面的职责:\n1. 组建优秀的产品团队。\n1. 规划产品全局战略，对产品组合负责。\n\n## 建设产品团队\n\n简单来说，发现适合做产品管理的人员，同时找出不适合的人员。发现有做产品潜质的人员时，应尽量给予其足够的时间和信任并监督和指导其不断进步，这样不仅提高了手下的能力，也是对自己能力的一种扩大，手下产品做得好也就是自己产品做得好。有些人天生就不合适做产品，所以需要及时发现以免浪费研发的时间和失去用户对产品的信任。\n\n## 规划公司的产品战略\n\n结合公司的商业战略规划产品战略，做到商业与用户需求的完美结合。同时需要解决不同产品经理提出的方案的冲突，做好整体产品的组合和规划。\n\n# 巴顿将军的忠告\n## 目标管理\n在构思一个产品功能且未形成最终方案的时候，应该充分发挥视觉设计，交互设计师的个人创造力，应该告诉他们接下来要做什么，而不是告诉他们如何做。让他们根据自己对市场的理解和对用户的调研来发挥想象。\n\n# 评估产品机会\n评估产品机会是产品经理的重要职责，通过评估产品机会可以淘汰bad idea,避免资源浪费。尤其对于资源有限的创业公司而言。\n\n为了评估产品机会，可以要求产品经理回答以下几个问题:\n1. 产品要解决什么问题?(产品价值)\n1. 为谁解决这个问题?(目标市场)\n1. 成功的机会有多大?(市场规模)\n1. 怎样判断产品成功与否?(度量指标或收益指标)\n1. 有哪些同类产品?(竞品分析)\n1. 为什么我们最适合做这个产品?(竞争优势)\n1. 时机是否合适?(市场时机)\n1. 如何把产品推向市场?(营销组合策略)\n1. 成功的必要条件是什么?(解决方案要满足的条件) \n1. 根据以上问题，得出评估结论?(继续或放弃)\n\n评估产品机会的时候不应该与具体解决方案一起讨论，否则容易造成具体方案遇到困难时就直接把产品机会一起否定掉。\n\n\n","slug":"how-to-create-products-customers-love","published":1,"updated":"2016-11-24T09:52:25.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fngq000bgm09y51au15s"},{"title":"effective-java-methods","date":"2016-06-22T06:34:20.000Z","_content":"\n# Methods\n\n“usability, robustness, and flexibility.”\n\n摘录来自: Joshua Bloch. “Effective Java (Jason Arnold's Library)”。 iBooks. \n\n## 检查参数有效性(check validity of params)\n\n早检查早发现早避免问题。Fail fast!\n\n未检查参数有效性可能导致的问题:\n1. 在执行过程中失败并抛出掩盖问题的异常。\n1. 正常返回但是返回的是错误的结果。\n1. 同样是正常返回，但是埋下了祸根，可能产生了其他状态有问题的数据，导致在不定时的将来产生不可预知的问题。\n\n<!-- more -->\n\n## 抛出异常\n对需要抛出异常的public方法，应该使用@throws说明。常见的如:`IllegalArgumentException`,`NPE`,`IndexOutOfBoundsException` etc. \n\n对于需要抛出异常的方法，应该使用javadoc尽量说明抛出该异常的具体条件，并且抛出异常时应该抛出具体的异常而不是一个父类，如避免抛出exception or throwable,让使用该方法的人知道如何合理有效的使用你提供的方法。\n\n对于nonpublic类型的方法，是由维护人员控制的，所以维护人员应该保证传入的参数都是有效的，只需要做assertion判断就行，没必要再检查然后抛出异常。\n\n## 失败原子性(failure atomicity)\n\n一般来说，一个失败的方法调用如果将处理的目标对象还原为调用方法之前的状态，就能称为是失败原子性的。\n通常达到这个效果的做法:\n* 使用immutable object.\n* 针对mutable object，常用方法就是检查参数的有效性，fail before modification!\n\nTalking is cheap, time to show some code!\n\n```java\n   /**\n     * Deletes the component at the specified index. Each component in\n     * this vector with an index greater or equal to the specified\n     * {@code index} is shifted downward to have an index one\n     * smaller than the value it had previously. The size of this vector\n     * is decreased by {@code 1}.\n     *\n     * <p>The index must be a value greater than or equal to {@code 0}\n     * and less than the current size of the vector.\n     *\n     * <p>This method is identical in functionality to the {@link #remove(int)}\n     * method (which is part of the {@link List} interface).  Note that the\n     * {@code remove} method returns the old value that was stored at the\n     * specified position.\n     *\n     * @param      index   the index of the object to remove\n     * @throws ArrayIndexOutOfBoundsException if the index is out of range\n     *         ({@code index < 0 || index >= size()})\n     */\n    public synchronized void removeElementAt(int index) {\n        modCount++;\n        if (index >= elementCount) {\n            throw new ArrayIndexOutOfBoundsException(index + \" >= \" +\n                                                     elementCount);\n        }\n        else if (index < 0) {\n            throw new ArrayIndexOutOfBoundsException(index);\n        }\n        int j = elementCount - index - 1;\n        if (j > 0) {\n            System.arraycopy(elementData, index + 1, elementData, index, j);\n        }\n        elementCount--;\n        elementData[elementCount] = null; /* to let gc do its work */\n    }\n```\n\n这段代码取自Vector中。在移除元素时提前检查数组是否越界，并在javadoc中使用`@throws`说明抛出的异常和触发条件。\n\n* 复制替换. 复制一份原始数据，对副本进行操作，顺利完成之后再替换原始数据。 如Collections.sort()在进行排序之前就是先将原始数据存在一个数组中，如果排序失败，原始数据原封不动。\n* \nJDK source code:\n```java\n    default void sort(Comparator<? super E> c) {\n        Object[] a = this.toArray();\n        Arrays.sort(a, (Comparator) c);\n        ListIterator<E> i = this.listIterator();\n        for (Object e : a) {\n            i.next();\n            i.set((E) e);\n        }\n    }\n```\n\n就以上看来，方法参数限制越严密越好，其实不然，如果一个方法对传入的参数都能够优雅的处理不用太多的限制对于使用该方法的人来说无疑是一大福音。\n\n__以上这几点看上去很简单朴实，但如果真正遵守并养成这些习惯，对代码质量的提高是可见一斑的。__\n\n## 保护性复制(Defensive copy)\n保护性复制是保护对象不变性，健壮性的一种策略。API提供者本意是想提供一个可靠稳定的对象，但往往不经意间对象的内部状态就被API的使用者所更改了，而且是无意识的。举个栗子:\n\n```java\nprivate class Period{\n        private Date start;\n        private Date end;\n\n        /**\n         * \n         * @param start\n         * @param end\n         *\n         * @throws IllegalArgumentException if start is greater than end\n         * @throws NullPointerException if start or end is null\n         */\n        public Period(Date start, Date end) {\n            if (start.compareTo(end)>0)\n                throw new IllegalArgumentException(\"start must less than end\");\n\n            this.start = new Date(start);\n            this.end = new Date(end);\n        }\n\n        public Date getStart() {\n            // return new Date(start);\n            return start;\n        }\n\n        public Date getEnd() {\n            // return new Date(end);\n            return end;\n        }\n    }\n```\n__The invariants of period can be broken easily!__\n传入start和end后，对start和end的修改会直接影响Period的内部状态,使用get方法获取到日期后也可以修改对象的内部状态,可以说这就是发布了一个不安全的对象。使用defensive copy就可以修复这个问题,在构造器和getter方法中都复制一份源对象即可。另外一种技巧也可以解决这个问题，period内部使用long来存储时间，就不用担心状态被更改。\n\n## 谨慎设计方法签名\n\n### 选择有意义的名字\n\n遵守约定的命名规范，如变量名词，方法动词开头等。\n\n### 不要过度提供工具方法\n\n过多的方法导致对象的维护难度提高，易用性下降。特别是对于接口而言，过多的方法导致实现起来比较困难，Think before in doing anything! 如果觉得没必要就不提供。\n\n### 避免过长的参数列表\n参数尽量不要超过四个，多了使用起来容易出错，特别当有多个相同类型的参数存在的时候,如果顺序弄错了，最终结果总是不对，也很难发下bug的所在。\n\n针对参数过多的情况常见的应对方式有:\n1. 拆分成几个方法，有可能会产生很多方法。\n2. 新建一个helper类包含这些参数，再将这个helper类作为参数传入。\n3. 利用Builder pattern。\n\n### 优先使用接口类型作为参数而不是实现类\n\n这个没什么好说的.\n\n### 使用含有两个元素的枚举代替boolean类型\n\n使用枚举不仅可读性更强，而且更容易扩展，可以添加其他选项和做转换处理等。\n\n\n\n","source":"_posts/effective-java-methods.md","raw":"---\ntitle: effective-java-methods\ndate: 2016-06-22 14:34:20\ncategories: java\ntags: [effective, java]\n---\n\n# Methods\n\n“usability, robustness, and flexibility.”\n\n摘录来自: Joshua Bloch. “Effective Java (Jason Arnold's Library)”。 iBooks. \n\n## 检查参数有效性(check validity of params)\n\n早检查早发现早避免问题。Fail fast!\n\n未检查参数有效性可能导致的问题:\n1. 在执行过程中失败并抛出掩盖问题的异常。\n1. 正常返回但是返回的是错误的结果。\n1. 同样是正常返回，但是埋下了祸根，可能产生了其他状态有问题的数据，导致在不定时的将来产生不可预知的问题。\n\n<!-- more -->\n\n## 抛出异常\n对需要抛出异常的public方法，应该使用@throws说明。常见的如:`IllegalArgumentException`,`NPE`,`IndexOutOfBoundsException` etc. \n\n对于需要抛出异常的方法，应该使用javadoc尽量说明抛出该异常的具体条件，并且抛出异常时应该抛出具体的异常而不是一个父类，如避免抛出exception or throwable,让使用该方法的人知道如何合理有效的使用你提供的方法。\n\n对于nonpublic类型的方法，是由维护人员控制的，所以维护人员应该保证传入的参数都是有效的，只需要做assertion判断就行，没必要再检查然后抛出异常。\n\n## 失败原子性(failure atomicity)\n\n一般来说，一个失败的方法调用如果将处理的目标对象还原为调用方法之前的状态，就能称为是失败原子性的。\n通常达到这个效果的做法:\n* 使用immutable object.\n* 针对mutable object，常用方法就是检查参数的有效性，fail before modification!\n\nTalking is cheap, time to show some code!\n\n```java\n   /**\n     * Deletes the component at the specified index. Each component in\n     * this vector with an index greater or equal to the specified\n     * {@code index} is shifted downward to have an index one\n     * smaller than the value it had previously. The size of this vector\n     * is decreased by {@code 1}.\n     *\n     * <p>The index must be a value greater than or equal to {@code 0}\n     * and less than the current size of the vector.\n     *\n     * <p>This method is identical in functionality to the {@link #remove(int)}\n     * method (which is part of the {@link List} interface).  Note that the\n     * {@code remove} method returns the old value that was stored at the\n     * specified position.\n     *\n     * @param      index   the index of the object to remove\n     * @throws ArrayIndexOutOfBoundsException if the index is out of range\n     *         ({@code index < 0 || index >= size()})\n     */\n    public synchronized void removeElementAt(int index) {\n        modCount++;\n        if (index >= elementCount) {\n            throw new ArrayIndexOutOfBoundsException(index + \" >= \" +\n                                                     elementCount);\n        }\n        else if (index < 0) {\n            throw new ArrayIndexOutOfBoundsException(index);\n        }\n        int j = elementCount - index - 1;\n        if (j > 0) {\n            System.arraycopy(elementData, index + 1, elementData, index, j);\n        }\n        elementCount--;\n        elementData[elementCount] = null; /* to let gc do its work */\n    }\n```\n\n这段代码取自Vector中。在移除元素时提前检查数组是否越界，并在javadoc中使用`@throws`说明抛出的异常和触发条件。\n\n* 复制替换. 复制一份原始数据，对副本进行操作，顺利完成之后再替换原始数据。 如Collections.sort()在进行排序之前就是先将原始数据存在一个数组中，如果排序失败，原始数据原封不动。\n* \nJDK source code:\n```java\n    default void sort(Comparator<? super E> c) {\n        Object[] a = this.toArray();\n        Arrays.sort(a, (Comparator) c);\n        ListIterator<E> i = this.listIterator();\n        for (Object e : a) {\n            i.next();\n            i.set((E) e);\n        }\n    }\n```\n\n就以上看来，方法参数限制越严密越好，其实不然，如果一个方法对传入的参数都能够优雅的处理不用太多的限制对于使用该方法的人来说无疑是一大福音。\n\n__以上这几点看上去很简单朴实，但如果真正遵守并养成这些习惯，对代码质量的提高是可见一斑的。__\n\n## 保护性复制(Defensive copy)\n保护性复制是保护对象不变性，健壮性的一种策略。API提供者本意是想提供一个可靠稳定的对象，但往往不经意间对象的内部状态就被API的使用者所更改了，而且是无意识的。举个栗子:\n\n```java\nprivate class Period{\n        private Date start;\n        private Date end;\n\n        /**\n         * \n         * @param start\n         * @param end\n         *\n         * @throws IllegalArgumentException if start is greater than end\n         * @throws NullPointerException if start or end is null\n         */\n        public Period(Date start, Date end) {\n            if (start.compareTo(end)>0)\n                throw new IllegalArgumentException(\"start must less than end\");\n\n            this.start = new Date(start);\n            this.end = new Date(end);\n        }\n\n        public Date getStart() {\n            // return new Date(start);\n            return start;\n        }\n\n        public Date getEnd() {\n            // return new Date(end);\n            return end;\n        }\n    }\n```\n__The invariants of period can be broken easily!__\n传入start和end后，对start和end的修改会直接影响Period的内部状态,使用get方法获取到日期后也可以修改对象的内部状态,可以说这就是发布了一个不安全的对象。使用defensive copy就可以修复这个问题,在构造器和getter方法中都复制一份源对象即可。另外一种技巧也可以解决这个问题，period内部使用long来存储时间，就不用担心状态被更改。\n\n## 谨慎设计方法签名\n\n### 选择有意义的名字\n\n遵守约定的命名规范，如变量名词，方法动词开头等。\n\n### 不要过度提供工具方法\n\n过多的方法导致对象的维护难度提高，易用性下降。特别是对于接口而言，过多的方法导致实现起来比较困难，Think before in doing anything! 如果觉得没必要就不提供。\n\n### 避免过长的参数列表\n参数尽量不要超过四个，多了使用起来容易出错，特别当有多个相同类型的参数存在的时候,如果顺序弄错了，最终结果总是不对，也很难发下bug的所在。\n\n针对参数过多的情况常见的应对方式有:\n1. 拆分成几个方法，有可能会产生很多方法。\n2. 新建一个helper类包含这些参数，再将这个helper类作为参数传入。\n3. 利用Builder pattern。\n\n### 优先使用接口类型作为参数而不是实现类\n\n这个没什么好说的.\n\n### 使用含有两个元素的枚举代替boolean类型\n\n使用枚举不仅可读性更强，而且更容易扩展，可以添加其他选项和做转换处理等。\n\n\n\n","slug":"effective-java-methods","published":1,"updated":"2016-11-24T09:52:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fngt000egm09p6q6kfm2"},{"title":"bootcamp","date":"2016-07-18T10:03:48.000Z","_content":"\n\n# mysql index and best practice handout\n\n\n讲讲MySQL的最佳实践和容易踩到的坑。\n\n<!-- more -->\n\n## syntax\n```sql\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    (create_definition,...)\n    [table_options]\n    [partition_options]\n\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    [(create_definition,...)]\n    [table_options]\n    [partition_options]\n    [IGNORE | REPLACE]\n    [AS] query_expression\n\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    { LIKE old_tbl_name | (LIKE old_tbl_name) }\n\ncreate_definition:\n    col_name column_definition\n  | [CONSTRAINT [symbol]] PRIMARY KEY [index_type] (index_col_name,...)\n      [index_option] ...\n  | {INDEX|KEY} [index_name] [index_type] (index_col_name,...)\n      [index_option] ...\n  | [CONSTRAINT [symbol]] UNIQUE [INDEX|KEY]\n      [index_name] [index_type] (index_col_name,...)\n      [index_option] ...\n  | {FULLTEXT|SPATIAL} [INDEX|KEY] [index_name] (index_col_name,...)\n      [index_option] ...\n  | [CONSTRAINT [symbol]] FOREIGN KEY\n      [index_name] (index_col_name,...) reference_definition\n  | CHECK (expr)\n\ncolumn_definition:\n    data_type [NOT NULL | NULL] [DEFAULT default_value]\n      [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY]\n      [COMMENT 'string']\n      [COLUMN_FORMAT {FIXED|DYNAMIC|DEFAULT}]\n      [STORAGE {DISK|MEMORY|DEFAULT}]\n      [reference_definition]\n  | data_type [GENERATED ALWAYS] AS (expression)\n      [VIRTUAL | STORED] [UNIQUE [KEY]] [COMMENT comment]\n      [NOT NULL | NULL] [[PRIMARY] KEY]\n\ndata_type:\n    BIT[(length)]\n  | TINYINT[(length)] [UNSIGNED] [ZEROFILL]\n  | SMALLINT[(length)] [UNSIGNED] [ZEROFILL]\n  | MEDIUMINT[(length)] [UNSIGNED] [ZEROFILL]\n  | INT[(length)] [UNSIGNED] [ZEROFILL]\n  | INTEGER[(length)] [UNSIGNED] [ZEROFILL]\n  | BIGINT[(length)] [UNSIGNED] [ZEROFILL]\n  | REAL[(length,decimals)] [UNSIGNED] [ZEROFILL]\n  | DOUBLE[(length,decimals)] [UNSIGNED] [ZEROFILL]\n  | FLOAT[(length,decimals)] [UNSIGNED] [ZEROFILL]\n  | DECIMAL[(length[,decimals])] [UNSIGNED] [ZEROFILL]\n  | NUMERIC[(length[,decimals])] [UNSIGNED] [ZEROFILL]\n  | DATE\n  | TIME[(fsp)]\n  | TIMESTAMP[(fsp)]\n  | DATETIME[(fsp)]\n  | YEAR\n  | CHAR[(length)] [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | VARCHAR(length) [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | BINARY[(length)]\n  | VARBINARY(length)\n  | TINYBLOB\n  | BLOB\n  | MEDIUMBLOB\n  | LONGBLOB\n  | TINYTEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | TEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | MEDIUMTEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | LONGTEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | ENUM(value1,value2,value3,...)\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | SET(value1,value2,value3,...)\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | JSON\n  | spatial_type\n\nindex_col_name:\n    col_name [(length)] [ASC | DESC]\n\nindex_type:\n    USING {BTREE | HASH}\n\nindex_option:\n    KEY_BLOCK_SIZE [=] value\n  | index_type\n  | WITH PARSER parser_name\n  | COMMENT 'string'\n\nreference_definition:\n    REFERENCES tbl_name (index_col_name,...)\n      [MATCH FULL | MATCH PARTIAL | MATCH SIMPLE]\n      [ON DELETE reference_option]\n      [ON UPDATE reference_option]\n\nreference_option:\n    RESTRICT | CASCADE | SET NULL | NO ACTION\n\ntable_options:\n    table_option [[,] table_option] ...\n\ntable_option:\n    ENGINE [=] engine_name\n  | AUTO_INCREMENT [=] value\n  | AVG_ROW_LENGTH [=] value\n  | [DEFAULT] CHARACTER SET [=] charset_name\n  | CHECKSUM [=] {0 | 1}\n  | [DEFAULT] COLLATE [=] collation_name\n  | COMMENT [=] 'string'\n  | COMPRESSION [=] {'ZLIB'|'LZ4'|'NONE'}\n  | CONNECTION [=] 'connect_string'\n  | DATA DIRECTORY [=] 'absolute path to directory'\n  | DELAY_KEY_WRITE [=] {0 | 1}\n  | ENCRYPTION [=] {'Y' | 'N'}\n  | INDEX DIRECTORY [=] 'absolute path to directory'\n  | INSERT_METHOD [=] { NO | FIRST | LAST }\n  | KEY_BLOCK_SIZE [=] value\n  | MAX_ROWS [=] value\n  | MIN_ROWS [=] value\n  | PACK_KEYS [=] {0 | 1 | DEFAULT}\n  | PASSWORD [=] 'string'\n  | ROW_FORMAT [=] {DEFAULT|DYNAMIC|FIXED|COMPRESSED|REDUNDANT|COMPACT}\n  | STATS_AUTO_RECALC [=] {DEFAULT|0|1}\n  | STATS_PERSISTENT [=] {DEFAULT|0|1}\n  | STATS_SAMPLE_PAGES [=] value\n  | TABLESPACE tablespace_name\n  | UNION [=] (tbl_name[,tbl_name]...)\n\npartition_options:\n    PARTITION BY\n        { [LINEAR] HASH(expr)\n        | [LINEAR] KEY [ALGORITHM={1|2}] (column_list)\n        | RANGE{(expr) | COLUMNS(column_list)}\n        | LIST{(expr) | COLUMNS(column_list)} }\n    [PARTITIONS num]\n    [SUBPARTITION BY\n        { [LINEAR] HASH(expr)\n        | [LINEAR] KEY [ALGORITHM={1|2}] (column_list) }\n      [SUBPARTITIONS num]\n    ]\n    [(partition_definition [, partition_definition] ...)]\n\npartition_definition:\n    PARTITION partition_name\n        [VALUES\n            {LESS THAN {(expr | value_list) | MAXVALUE}\n            |\n            IN (value_list)}]\n        [[STORAGE] ENGINE [=] engine_name]\n        [COMMENT [=] 'comment_text' ]\n        [DATA DIRECTORY [=] 'data_dir']\n        [INDEX DIRECTORY [=] 'index_dir']\n        [MAX_ROWS [=] max_number_of_rows]\n        [MIN_ROWS [=] min_number_of_rows]\n        [TABLESPACE [=] tablespace_name]\n        [(subpartition_definition [, subpartition_definition] ...)]\n\nsubpartition_definition:\n    SUBPARTITION logical_name\n        [[STORAGE] ENGINE [=] engine_name]\n        [COMMENT [=] 'comment_text' ]\n        [DATA DIRECTORY [=] 'data_dir']\n        [INDEX DIRECTORY [=] 'index_dir']\n        [MAX_ROWS [=] max_number_of_rows]\n        [MIN_ROWS [=] min_number_of_rows]\n        [TABLESPACE [=] tablespace_name]\n\nquery_expression:\n    SELECT ...   (Some valid select or union statement)\n```\n\n## 选择合适的数据类型\n物尽其用。如果存储空间较小的数据类型能满足需求，就不要使用更大的类型。\n\n### 整数\nTINYINT(8),SMALLINT(16),MEDIUMINT(24),INT(32),BIGINT(64) <UNSIGNED>. 如果明确存储的值不为负数，加上unsigned可有效扩大值域范围。\n\n### 实数\n虽然mysql提供了FLOAT,DOUBLE,DECIMAL来存储带精度的小数，但是实际开发中通常的做法是将其转换成整数存储，避免出现各种因精度导致的问题。\n\n### 字符串\n#### varchar\n可变长，适用于大多数情况。\n#### char\n选择合适的使用场景，如存储密码和手机号等等。\n\n### 日期和时间\n\n#### datetime\n\n保存时间范围从1001-9999，精度为秒，是mysql中表示时间范围最大的类型，且与时区无关。空间占用8字节。\n\n#### timestamp\nunix timestamp，表示从1970-01-01午夜开始的时间。可覆盖的最大时间为2038年，与时区相关，可根据时区自动变化，空间占用4字节。\n\n这两种日期时间类型都只支持秒级别的数据，如果需要存储毫秒可以考虑使用bigint来存储。\n\n### 谨慎选择标识符类型\n1. 整数类型。 整数是最理想的作为标识列的数据类型，比较很快，并且可以使用auto_increment. 顺序I/O的性能要比随机好很多。\n2. 字符串类型。 实际工作中可能会遇到使用UUID,SHA1产生的随机字符串来作为标识列，用字符串来作为标识列不仅消耗大而且比较慢，此外会导致插入，查询都变成随机I/O，而且可能会产生大量页分裂的情况，对性能有很大的影响。可考虑将其转换成整数存储。\n\n## 表设计注意事项\n\n### 合理的列长度\n同一个表中不要设计过多的列，否则会导致数据行在mysql server和数据库引擎之前转换时产生较大的开销。\n### 合理使用null\n前面说过尽量不要存在默认值为null的情况，但是如果实际情况确实为一个未知的值，也不能硬塞一个不合理的值充数，否则编写代码时还要对其进行特殊处理，更严重的是导致bug的产生。如数据库存在一个`-1`的默认值,在传递给iOS客户端时，如果客户端使用的类型是unsigned int，就会产生一个未知的整数，严重的导致应用崩溃，次之则是产生困惑的数据。\n\n## null 比较查询注意事项\n不要使用 = <> 比较null值。使用 is null ,is not null. 灵活使用IF(),IFNULL(). 除非有特殊需要，尽量避免使用null值，null值会使得mysql很难对查询进行优化，尤其是不要在有索引的列上允许null存在。\n\n## 字段维护注意事项\n\n1. 新增字段尽量要有默认值,且设置为NOT NULL,有利于数据检索优化。\n2. 增加多个字段时，使用一条语句修改，避免多次单独创建。\n3. 字段新增或结构变化应该先于应用上线，避免上线后报SQL错误。\n4. 若是删除字段，应该等待应用上线运行稳定后再进行字段删除，避免误删。\n5. 若字段类型更改导致不兼容时，可能会停机维护，一般可通过其他方式避免停机。\n6. 若涉及索引变更，应在应用上线前增加新的索引，上线运行稳定之后再删除旧的索引。\n\n## 风格\n### 命名\n* 采用26个英文字母(区分大小写)和0-9这十个自然数,加上下划线'_'组成,共63个字符.不能出现其他字符(注释除外).\n* 外键名用`fk_开头，后面跟该外键所在的表名和对应的主表名（不含t_）`。子表名和父表名自己用下划线（_）分隔。外键名长度不能超过30个字符。如果过长，可对表名进行缩写。缩写规则同表名的缩写规则。外键名用小写的英文单词来表示。\n唯一性索引用`uk_开头，后面跟字段名。一般性索引用idx_开头`，后面跟字段名\n* 备份数据表名使用正式表名加上备份时间组成，如，`branch_user_20140326`\n\n### 建表相关\n\n* innodb建表，主键用无意义的自增主键。\n* 禁用外键约束，由应用程序实现参照完整性\n* 字段需设置为非空，需设置字段默认值。\n* 用INNODB引擎建表。\n* 表和每个字段都添加简短的comments\n* 用尽量少的存储空间来存数一个字段的数据\n    1. 能用int的就不用char或者varchar\n    1. 能用tinyint的就不用int\n    1. 能用varchar(20)的就不用varchar(255)\n* 在建表语句后面加上使用的数据引擎和索引还有编码格式\n```sql\nCREATE TABLE `db`.`tbl_name` (\n  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `user_id` int(11)  NOT NULL DEFAULT '0' COMMENT '用户ID',\n  `start_time` DATETIME DEFAULT NULL COMMENT '创建时间',\n  PRIMARY KEY (`id`),\n  UNIQUE INDEX `uk_user` (`user_id`)\n)ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='清理浏览记录的时间’;\n```\n* 修改或者新建表的时候,不需要加库命，也不要写if not exist这种语句，建表之前请确定是否存在原表,比如\n```sql\nalter table `user_token` add column `version` varchar(64) DEFAULT NULL\nCOMMENT '版本号';\n```\n而不是写\n```sql\nalter table `db`.`user_token` add column `version` varchar(64) DEFAULT NULL COMMENT '版本号';\n```\n\n### 修改表结构\n* 多步合一,禁止单表多个更改字段，用多次alter table命令 ,在操作时，为了尽可能减少影响和操作时间，对同一个表进行的多步操作进行合并。比如对同一个表既加字段、又加索引，那么就应该写成一条语句。减少复制临时表的时间。\n* 如果只是改变一个字段的默认值，那么使用`alter table user alter column id set default 5;`这种语法.\n\n## 基本命令\n`show databases`,`show tables`,`desc tableName`,`show create table tableName`.\n\n## 查询技巧\n```\nwhere 1=1\n\nselect\ng1.id\nfrom group g1\nwhere\n1 = (select count(g2.id) from group g2 where g1.user_id=g2.user_id and g1.created_time <= g2.created_time );\n```\n\n## 索引\n\n### B Tree 索引\n实现为B+ TREE.\n### hash索引\n索引中存放的hash值和指向数据行的指针。\n### 聚簇索引。\n聚簇索引严格来说不是一种索引类型，只是一种数据存储方式。主键就是一种聚簇索引，索引和数据行都存放在leaf上。\n### 覆盖索引\n一个索引包含所有查询字段的值，则称为覆盖索引。\n优点:\n1. 可避免回表查询，极大提高效率。\n2. 完全顺序I/O。\n缺点:\n因为要存储列值，所以只适用于B TREE 索引。\n### 索引合并\n如果表中存在多个单列索引，在同时使用这几个单列索引时，mysql会采用一种索引合并的算法来同时使用这几个索引，这个过程会耗费大量的CPU和内存资源，出现这种情况可以说设计的索引就是一个失败的案例。 通过EXPALIN可以查看到是否使用了索引合并。\n### 索引选择性\n索引选择性=唯一值/总记录数。 索引选择性越高查询性能越好。可以据此判断索引设计的好坏。\n\n","source":"_posts/bootcamp.md","raw":"---\ntitle: bootcamp\ndate: 2016-07-18 18:03:48\ntags: MySQL\n---\n\n\n# mysql index and best practice handout\n\n\n讲讲MySQL的最佳实践和容易踩到的坑。\n\n<!-- more -->\n\n## syntax\n```sql\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    (create_definition,...)\n    [table_options]\n    [partition_options]\n\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    [(create_definition,...)]\n    [table_options]\n    [partition_options]\n    [IGNORE | REPLACE]\n    [AS] query_expression\n\nCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name\n    { LIKE old_tbl_name | (LIKE old_tbl_name) }\n\ncreate_definition:\n    col_name column_definition\n  | [CONSTRAINT [symbol]] PRIMARY KEY [index_type] (index_col_name,...)\n      [index_option] ...\n  | {INDEX|KEY} [index_name] [index_type] (index_col_name,...)\n      [index_option] ...\n  | [CONSTRAINT [symbol]] UNIQUE [INDEX|KEY]\n      [index_name] [index_type] (index_col_name,...)\n      [index_option] ...\n  | {FULLTEXT|SPATIAL} [INDEX|KEY] [index_name] (index_col_name,...)\n      [index_option] ...\n  | [CONSTRAINT [symbol]] FOREIGN KEY\n      [index_name] (index_col_name,...) reference_definition\n  | CHECK (expr)\n\ncolumn_definition:\n    data_type [NOT NULL | NULL] [DEFAULT default_value]\n      [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY]\n      [COMMENT 'string']\n      [COLUMN_FORMAT {FIXED|DYNAMIC|DEFAULT}]\n      [STORAGE {DISK|MEMORY|DEFAULT}]\n      [reference_definition]\n  | data_type [GENERATED ALWAYS] AS (expression)\n      [VIRTUAL | STORED] [UNIQUE [KEY]] [COMMENT comment]\n      [NOT NULL | NULL] [[PRIMARY] KEY]\n\ndata_type:\n    BIT[(length)]\n  | TINYINT[(length)] [UNSIGNED] [ZEROFILL]\n  | SMALLINT[(length)] [UNSIGNED] [ZEROFILL]\n  | MEDIUMINT[(length)] [UNSIGNED] [ZEROFILL]\n  | INT[(length)] [UNSIGNED] [ZEROFILL]\n  | INTEGER[(length)] [UNSIGNED] [ZEROFILL]\n  | BIGINT[(length)] [UNSIGNED] [ZEROFILL]\n  | REAL[(length,decimals)] [UNSIGNED] [ZEROFILL]\n  | DOUBLE[(length,decimals)] [UNSIGNED] [ZEROFILL]\n  | FLOAT[(length,decimals)] [UNSIGNED] [ZEROFILL]\n  | DECIMAL[(length[,decimals])] [UNSIGNED] [ZEROFILL]\n  | NUMERIC[(length[,decimals])] [UNSIGNED] [ZEROFILL]\n  | DATE\n  | TIME[(fsp)]\n  | TIMESTAMP[(fsp)]\n  | DATETIME[(fsp)]\n  | YEAR\n  | CHAR[(length)] [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | VARCHAR(length) [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | BINARY[(length)]\n  | VARBINARY(length)\n  | TINYBLOB\n  | BLOB\n  | MEDIUMBLOB\n  | LONGBLOB\n  | TINYTEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | TEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | MEDIUMTEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | LONGTEXT [BINARY]\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | ENUM(value1,value2,value3,...)\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | SET(value1,value2,value3,...)\n      [CHARACTER SET charset_name] [COLLATE collation_name]\n  | JSON\n  | spatial_type\n\nindex_col_name:\n    col_name [(length)] [ASC | DESC]\n\nindex_type:\n    USING {BTREE | HASH}\n\nindex_option:\n    KEY_BLOCK_SIZE [=] value\n  | index_type\n  | WITH PARSER parser_name\n  | COMMENT 'string'\n\nreference_definition:\n    REFERENCES tbl_name (index_col_name,...)\n      [MATCH FULL | MATCH PARTIAL | MATCH SIMPLE]\n      [ON DELETE reference_option]\n      [ON UPDATE reference_option]\n\nreference_option:\n    RESTRICT | CASCADE | SET NULL | NO ACTION\n\ntable_options:\n    table_option [[,] table_option] ...\n\ntable_option:\n    ENGINE [=] engine_name\n  | AUTO_INCREMENT [=] value\n  | AVG_ROW_LENGTH [=] value\n  | [DEFAULT] CHARACTER SET [=] charset_name\n  | CHECKSUM [=] {0 | 1}\n  | [DEFAULT] COLLATE [=] collation_name\n  | COMMENT [=] 'string'\n  | COMPRESSION [=] {'ZLIB'|'LZ4'|'NONE'}\n  | CONNECTION [=] 'connect_string'\n  | DATA DIRECTORY [=] 'absolute path to directory'\n  | DELAY_KEY_WRITE [=] {0 | 1}\n  | ENCRYPTION [=] {'Y' | 'N'}\n  | INDEX DIRECTORY [=] 'absolute path to directory'\n  | INSERT_METHOD [=] { NO | FIRST | LAST }\n  | KEY_BLOCK_SIZE [=] value\n  | MAX_ROWS [=] value\n  | MIN_ROWS [=] value\n  | PACK_KEYS [=] {0 | 1 | DEFAULT}\n  | PASSWORD [=] 'string'\n  | ROW_FORMAT [=] {DEFAULT|DYNAMIC|FIXED|COMPRESSED|REDUNDANT|COMPACT}\n  | STATS_AUTO_RECALC [=] {DEFAULT|0|1}\n  | STATS_PERSISTENT [=] {DEFAULT|0|1}\n  | STATS_SAMPLE_PAGES [=] value\n  | TABLESPACE tablespace_name\n  | UNION [=] (tbl_name[,tbl_name]...)\n\npartition_options:\n    PARTITION BY\n        { [LINEAR] HASH(expr)\n        | [LINEAR] KEY [ALGORITHM={1|2}] (column_list)\n        | RANGE{(expr) | COLUMNS(column_list)}\n        | LIST{(expr) | COLUMNS(column_list)} }\n    [PARTITIONS num]\n    [SUBPARTITION BY\n        { [LINEAR] HASH(expr)\n        | [LINEAR] KEY [ALGORITHM={1|2}] (column_list) }\n      [SUBPARTITIONS num]\n    ]\n    [(partition_definition [, partition_definition] ...)]\n\npartition_definition:\n    PARTITION partition_name\n        [VALUES\n            {LESS THAN {(expr | value_list) | MAXVALUE}\n            |\n            IN (value_list)}]\n        [[STORAGE] ENGINE [=] engine_name]\n        [COMMENT [=] 'comment_text' ]\n        [DATA DIRECTORY [=] 'data_dir']\n        [INDEX DIRECTORY [=] 'index_dir']\n        [MAX_ROWS [=] max_number_of_rows]\n        [MIN_ROWS [=] min_number_of_rows]\n        [TABLESPACE [=] tablespace_name]\n        [(subpartition_definition [, subpartition_definition] ...)]\n\nsubpartition_definition:\n    SUBPARTITION logical_name\n        [[STORAGE] ENGINE [=] engine_name]\n        [COMMENT [=] 'comment_text' ]\n        [DATA DIRECTORY [=] 'data_dir']\n        [INDEX DIRECTORY [=] 'index_dir']\n        [MAX_ROWS [=] max_number_of_rows]\n        [MIN_ROWS [=] min_number_of_rows]\n        [TABLESPACE [=] tablespace_name]\n\nquery_expression:\n    SELECT ...   (Some valid select or union statement)\n```\n\n## 选择合适的数据类型\n物尽其用。如果存储空间较小的数据类型能满足需求，就不要使用更大的类型。\n\n### 整数\nTINYINT(8),SMALLINT(16),MEDIUMINT(24),INT(32),BIGINT(64) <UNSIGNED>. 如果明确存储的值不为负数，加上unsigned可有效扩大值域范围。\n\n### 实数\n虽然mysql提供了FLOAT,DOUBLE,DECIMAL来存储带精度的小数，但是实际开发中通常的做法是将其转换成整数存储，避免出现各种因精度导致的问题。\n\n### 字符串\n#### varchar\n可变长，适用于大多数情况。\n#### char\n选择合适的使用场景，如存储密码和手机号等等。\n\n### 日期和时间\n\n#### datetime\n\n保存时间范围从1001-9999，精度为秒，是mysql中表示时间范围最大的类型，且与时区无关。空间占用8字节。\n\n#### timestamp\nunix timestamp，表示从1970-01-01午夜开始的时间。可覆盖的最大时间为2038年，与时区相关，可根据时区自动变化，空间占用4字节。\n\n这两种日期时间类型都只支持秒级别的数据，如果需要存储毫秒可以考虑使用bigint来存储。\n\n### 谨慎选择标识符类型\n1. 整数类型。 整数是最理想的作为标识列的数据类型，比较很快，并且可以使用auto_increment. 顺序I/O的性能要比随机好很多。\n2. 字符串类型。 实际工作中可能会遇到使用UUID,SHA1产生的随机字符串来作为标识列，用字符串来作为标识列不仅消耗大而且比较慢，此外会导致插入，查询都变成随机I/O，而且可能会产生大量页分裂的情况，对性能有很大的影响。可考虑将其转换成整数存储。\n\n## 表设计注意事项\n\n### 合理的列长度\n同一个表中不要设计过多的列，否则会导致数据行在mysql server和数据库引擎之前转换时产生较大的开销。\n### 合理使用null\n前面说过尽量不要存在默认值为null的情况，但是如果实际情况确实为一个未知的值，也不能硬塞一个不合理的值充数，否则编写代码时还要对其进行特殊处理，更严重的是导致bug的产生。如数据库存在一个`-1`的默认值,在传递给iOS客户端时，如果客户端使用的类型是unsigned int，就会产生一个未知的整数，严重的导致应用崩溃，次之则是产生困惑的数据。\n\n## null 比较查询注意事项\n不要使用 = <> 比较null值。使用 is null ,is not null. 灵活使用IF(),IFNULL(). 除非有特殊需要，尽量避免使用null值，null值会使得mysql很难对查询进行优化，尤其是不要在有索引的列上允许null存在。\n\n## 字段维护注意事项\n\n1. 新增字段尽量要有默认值,且设置为NOT NULL,有利于数据检索优化。\n2. 增加多个字段时，使用一条语句修改，避免多次单独创建。\n3. 字段新增或结构变化应该先于应用上线，避免上线后报SQL错误。\n4. 若是删除字段，应该等待应用上线运行稳定后再进行字段删除，避免误删。\n5. 若字段类型更改导致不兼容时，可能会停机维护，一般可通过其他方式避免停机。\n6. 若涉及索引变更，应在应用上线前增加新的索引，上线运行稳定之后再删除旧的索引。\n\n## 风格\n### 命名\n* 采用26个英文字母(区分大小写)和0-9这十个自然数,加上下划线'_'组成,共63个字符.不能出现其他字符(注释除外).\n* 外键名用`fk_开头，后面跟该外键所在的表名和对应的主表名（不含t_）`。子表名和父表名自己用下划线（_）分隔。外键名长度不能超过30个字符。如果过长，可对表名进行缩写。缩写规则同表名的缩写规则。外键名用小写的英文单词来表示。\n唯一性索引用`uk_开头，后面跟字段名。一般性索引用idx_开头`，后面跟字段名\n* 备份数据表名使用正式表名加上备份时间组成，如，`branch_user_20140326`\n\n### 建表相关\n\n* innodb建表，主键用无意义的自增主键。\n* 禁用外键约束，由应用程序实现参照完整性\n* 字段需设置为非空，需设置字段默认值。\n* 用INNODB引擎建表。\n* 表和每个字段都添加简短的comments\n* 用尽量少的存储空间来存数一个字段的数据\n    1. 能用int的就不用char或者varchar\n    1. 能用tinyint的就不用int\n    1. 能用varchar(20)的就不用varchar(255)\n* 在建表语句后面加上使用的数据引擎和索引还有编码格式\n```sql\nCREATE TABLE `db`.`tbl_name` (\n  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `user_id` int(11)  NOT NULL DEFAULT '0' COMMENT '用户ID',\n  `start_time` DATETIME DEFAULT NULL COMMENT '创建时间',\n  PRIMARY KEY (`id`),\n  UNIQUE INDEX `uk_user` (`user_id`)\n)ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='清理浏览记录的时间’;\n```\n* 修改或者新建表的时候,不需要加库命，也不要写if not exist这种语句，建表之前请确定是否存在原表,比如\n```sql\nalter table `user_token` add column `version` varchar(64) DEFAULT NULL\nCOMMENT '版本号';\n```\n而不是写\n```sql\nalter table `db`.`user_token` add column `version` varchar(64) DEFAULT NULL COMMENT '版本号';\n```\n\n### 修改表结构\n* 多步合一,禁止单表多个更改字段，用多次alter table命令 ,在操作时，为了尽可能减少影响和操作时间，对同一个表进行的多步操作进行合并。比如对同一个表既加字段、又加索引，那么就应该写成一条语句。减少复制临时表的时间。\n* 如果只是改变一个字段的默认值，那么使用`alter table user alter column id set default 5;`这种语法.\n\n## 基本命令\n`show databases`,`show tables`,`desc tableName`,`show create table tableName`.\n\n## 查询技巧\n```\nwhere 1=1\n\nselect\ng1.id\nfrom group g1\nwhere\n1 = (select count(g2.id) from group g2 where g1.user_id=g2.user_id and g1.created_time <= g2.created_time );\n```\n\n## 索引\n\n### B Tree 索引\n实现为B+ TREE.\n### hash索引\n索引中存放的hash值和指向数据行的指针。\n### 聚簇索引。\n聚簇索引严格来说不是一种索引类型，只是一种数据存储方式。主键就是一种聚簇索引，索引和数据行都存放在leaf上。\n### 覆盖索引\n一个索引包含所有查询字段的值，则称为覆盖索引。\n优点:\n1. 可避免回表查询，极大提高效率。\n2. 完全顺序I/O。\n缺点:\n因为要存储列值，所以只适用于B TREE 索引。\n### 索引合并\n如果表中存在多个单列索引，在同时使用这几个单列索引时，mysql会采用一种索引合并的算法来同时使用这几个索引，这个过程会耗费大量的CPU和内存资源，出现这种情况可以说设计的索引就是一个失败的案例。 通过EXPALIN可以查看到是否使用了索引合并。\n### 索引选择性\n索引选择性=唯一值/总记录数。 索引选择性越高查询性能越好。可以据此判断索引设计的好坏。\n\n","slug":"bootcamp","published":1,"updated":"2016-11-24T09:54:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fngw000kgm09yuw1li5s"},{"title":"Spring可扩展的XML配置","date":"2016-11-01T03:58:34.000Z","_content":"\n# Spring 可扩展的XML配置\n\nSpring 自从2.0开始就为基础的xml格式提供了一个基于xml schema的扩展机制，用于定义和配置beans。本文基于此简单讲解如果定义自己的`BeanDefinitionParser`和如何将定义好的`parsers`集成到`Spring IoC container`中。\n\n创建一个xml配置扩展可以通过以下4步完成：\n\n1. 创建一个xml schema来描述你自定的xml元素。\n2. 编写一个`NamespaceHandler`的具体实现。\n3. 编写一个或者多个`BeanDefinitionParser`的实现。主要的工作都在此步骤完成。\n4. 关联`xsd`,`NamespaceHandler`。\n\n下面依照以上四个步骤并附一个示例详细讲解。完整代码放在码云上:https://git.oschina.net/android-speeder/springcustomxml.git\n\n<!-- more -->\n\n\n## 创建schema文件\n\n创建一个spring可以用的xml配置扩展首先需要定义一个xml schema来描述这个扩展。\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<xsd:schema xmlns=\"http://daveztong.github.io/schema/dz\"\n            xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"\n            xmlns:beans=\"http://www.springframework.org/schema/beans\"\n            targetNamespace=\"http://daveztong.github.io/schema/dz\"\n            elementFormDefault=\"qualified\"\n            attributeFormDefault=\"unqualified\">\n\n    <xsd:import namespace=\"http://www.springframework.org/schema/beans\"/>\n\n    <xsd:element name=\"person\">\n        <xsd:complexType>\n            <xsd:complexContent>\n                <xsd:extension base=\"beans:identifiedType\">\n                    <xsd:attribute name=\"name\" type=\"xsd:string\" use=\"required\"/>\n                    <xsd:attribute name=\"age\" type=\"xsd:int\"/>\n                </xsd:extension>\n            </xsd:complexContent>\n        </xsd:complexType>\n    </xsd:element>\n\n</xsd:schema>\n```\n\n注意`<xsd:extension base=\"beans:identifiedType\">`表示该tag含有一个id属性并且会被spring container用于识别该bean。使用该属性的前提是需要导入`<xsd:import namespace=\"http://www.springframework.org/schema/beans\"/>`。\n\n\n\n## 实现NamespaceHandler\n\n当spring在解析xml时遇到该namespace就需要使用自定义的`Namespacehandler`去解析所有该名称空间下的元素。\n\n`NamespaceHandler`只包含三个方法:\n\n* `init()`: 用于初始化`NamespaceHandler`。\n* `BeanDefinition parse(Element, ParserContext)`：当spring遇到顶级的元素时才会调用。该方法可以直接返回一个bean definition或者自己注册一个。\n* `BeanDefinitionHolder decorate(Node, BeanDefinitionHolder, ParserContext)`:当spring遇到属性定义或者嵌套在不同名称空间下的元素时才会被调用。\n\n\n\n我们可以自己实现`NamespaceHandler`,但是基于spring的惯例，一般都会提供一个基础类简化开发人员的工作，所以我们可以直接继承spring提供的`NamespaceHandlerSupport`。\n\n```java\npackage io.github.daveztong;\n\nimport org.springframework.beans.factory.xml.NamespaceHandlerSupport;\n\n/**\n * Created by tangwei on 2016/10/31.\n */\npublic class DZNamespaceHandler extends NamespaceHandlerSupport{\n    @Override\n    public void init() {\n        registerBeanDefinitionParser(\"person\",new PersonBeanDefinitionParser());\n    }\n}\n```\n\n可以看到`DZNamespaceHandler`的代码量很少，因为真正的解析工作都委托给了`BeanDefinitionParser`。\t`NamespaceHandler`支持注册任意多个`BeanDefinitionParser`,当其需要解析其所负责的名称空间下的元素时就会将解析工作委托给注册的`BeanDefinitionParser`。\n\n## 实现`BeanDefinitionParser`\n\n当`NamespaceHandler`遇到一个与注册列表中key匹配的xml元素时就会将该元素的解析任务交给与key对应的`BeanDefinitionParser`。在本例中则是`PersonBeanDefinitionParser`。也就是说一个`BeanDefinitionParser`仅负责解析定义在指定schema中的一个唯一顶级的xml元素。在parser中我们可以访问到其负责解析的元素和子元素的内容。\n\n```java\npackage io.github.daveztong;\n\nimport org.springframework.beans.factory.support.BeanDefinitionBuilder;\nimport org.springframework.beans.factory.xml.AbstractSingleBeanDefinitionParser;\nimport org.springframework.util.StringUtils;\nimport org.w3c.dom.Element;\n\n/**\n * Created by tangwei on 2016/10/31.\n */\npublic class PersonBeanDefinitionParser extends AbstractSingleBeanDefinitionParser {\n    @Override\n    protected Class<?> getBeanClass(Element element) {\n        return Person.class;\n    }\n\n    @Override\n    protected void doParse(Element element, BeanDefinitionBuilder builder) {\n        String name = element.getAttribute(\"name\");\n        if (StringUtils.hasText(name)) {\n            builder.addPropertyValue(\"name\", name);\n        }\n\n        String age = element.getAttribute(\"age\");\n        if (StringUtils.hasText(age)) {\n            builder.addPropertyValue(\"age\", Integer.parseInt(age));\n        }\n    }\n}\n```\n\n编码部分就这么多，是不是so easy! 可能有人会疑问，为什么没有看到`BeanDefiniiton`的创建，那是因为创建的工作由`AbstractSingleBeanDefinitionParser#parseInternal`完成了。\n\n```java\n@Override\n\tprotected final AbstractBeanDefinition parseInternal(Element element, ParserContext parserContext) {\n\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition();\n\t\tString parentName = getParentName(element);\n\t\tif (parentName != null) {\n\t\t\tbuilder.getRawBeanDefinition().setParentName(parentName);\n\t\t}\n\t\tClass<?> beanClass = getBeanClass(element);\n\t\tif (beanClass != null) {\n\t\t\tbuilder.getRawBeanDefinition().setBeanClass(beanClass);\n\t\t}\n\t\telse {\n\t\t\tString beanClassName = getBeanClassName(element);\n\t\t\tif (beanClassName != null) {\n\t\t\t\tbuilder.getRawBeanDefinition().setBeanClassName(beanClassName);\n\t\t\t}\n\t\t}\n\t\tbuilder.getRawBeanDefinition().setSource(parserContext.extractSource(element));\n\t\tif (parserContext.isNested()) {\n\t\t\t// Inner bean definition must receive same scope as containing bean.\n\t\t\tbuilder.setScope(parserContext.getContainingBeanDefinition().getScope());\n\t\t}\n\t\tif (parserContext.isDefaultLazyInit()) {\n\t\t\t// Default-lazy-init applies to custom bean definitions as well.\n\t\t\tbuilder.setLazyInit(true);\n\t\t}\n\t\tdoParse(element, parserContext, builder);\n\t\treturn builder.getBeanDefinition();\n\t}\n```\n\nThe last statement `builder.getBeanDefinition();`返回了我们需要的bean. 继续看builder.getBeanDefinition()的代码:\n\n```java\npublic AbstractBeanDefinition getBeanDefinition() {\n\t\tthis.beanDefinition.validate();\n\t\treturn this.beanDefinition;\n\t}\n```\n\nThat's our bean!\n\n编码部分是完成了，但是spring还不知道他们的存在，接下来就需要让spring aware of them!(aware是个很关键的词啊，在spring的代码里随处可见^_^)\n\n\n\n## 注册handler and schema\n\n要让spring aware of out handler and xsd schema,我们需要在两个特殊的properties文件中注册他们。这些properties文件需要放在`META-INF`目录下面,并且可以和jar包一起发布。spring的解析框架通过这些特殊的properties文件就能pick up our handler and schema!\n\n\n\n### META-INF/spring.handlers\n\n`spring.handlers`包含了 xml schema uri 和namespace handler之间的k-v映射关系，如下:\n\n```properties\nhttp\\://daveztong.github.io/schema/dz=io.github.daveztong.DZNamespaceHandler\n```\n\n注意，因为`:`在properties文件中是个合法的分隔符，所以需要escape以下！\n\n其中URI部分是自定义的namespace扩展，必须与xsd中的`targetNamespace`完全匹配。\n\n### META-INF/spring.schemas\n\n`spring.schemas`中包含了xml schema uri(对应`xsi:schemaLocation`的值)与classpath resources的映射关系。如果这个文件不存在，spring默认会从网上加载`xsi:schemaLocation`中所定义的schema。有个这个映射文件，spring就会从classpath中加载而不再联网查找。\n\n```properties\nhttp\\://daveztong.github.io/schema/dz/dz.xsd=io/github/daveztong/schema/dz/dz.xsd\n```\n\n\n\n## Now,time to test\n\n使用xml定义person bean: spring-beans.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:dz=\"http://daveztong.github.io/schema/dz\"\n       xsi:schemaLocation=\"\nhttp://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\nhttp://daveztong.github.io/schema/dz http://daveztong.github.io/schema/dz/dz.xsd\">\n\n    <!-- as a top-level bean -->\n    <dz:person age=\"22\" id=\"person\" name=\"tangwei\"/>\n\n</beans>\n```\n\n\n\n为了演示效果，这里使用spring boot来快速测试: `App.java`\n\n```java\npackage io.github.daveztong;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.context.annotation.ImportResource;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\nimport javax.annotation.Resource;\n\n/**\n * Created by tangwei on 2016/11/1.\n */\n@EnableAutoConfiguration\n@Controller\n@ImportResource(\"classpath:spring-beans.xml\")\npublic class App {\n\n    @Resource\n    private Person person;\n\n    public static void main(String[] args) {\n        SpringApplication.run(App.class);\n    }\n\n    @RequestMapping(\"/\")\n    @ResponseBody\n    public String showPerson() {\n        return person.toString();\n    }\n}\n```\n\n\n\n访问http://localhost:8080/ ,dada:\n\n```\nPerson{age=22, name='tangwei'}\n```\n\n\n\n说了这么多，到底谁在用这个，能干啥呢！\n\n## Dubbo xml 配置扩展\n\nDubbo 在国内开源RPC界算是比较知名的，她其实采用的就是这种方式解析自定义的配置。dubbo jar 包结构:\n\n![dubbo jar structure](http://ww4.sinaimg.cn/large/94dc19degw1f9cgo55oetj209q06hmxg.jpg)\n\n\n\nspring.handlers:\n\n`http\\://code.alibabatech.com/schema/dubbo=com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler`\n\nspring.schemas:\n\n`http\\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd`\n\nNamespaceHandler实现为:\n\n```java\npublic class DubboNamespaceHandler extends NamespaceHandlerSupport {\n\n\tstatic {\n\t\tVersion.checkDuplicate(DubboNamespaceHandler.class);\n\t}\n\n\tpublic void init() {\n\t    registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true));\n        registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true));\n        registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true));\n        registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true));\n        registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true));\n        registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true));\n        registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true));\n        registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true));\n        registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false));\n        registerBeanDefinitionParser(\"annotation\", new DubboBeanDefinitionParser(AnnotationBean.class, true));\n    }\n\n}\n```\n\n该handler注册了所有的bean definition parser!\n\n了解这种机制后，我们也可以根据自己需要做任何配置扩展。So cool!\n","source":"_posts/Spring可扩展的XML配置.md","raw":"---\ntitle: Spring可扩展的XML配置\ndate: 2016-11-01 11:58:34\ntags: dubbo\n---\n\n# Spring 可扩展的XML配置\n\nSpring 自从2.0开始就为基础的xml格式提供了一个基于xml schema的扩展机制，用于定义和配置beans。本文基于此简单讲解如果定义自己的`BeanDefinitionParser`和如何将定义好的`parsers`集成到`Spring IoC container`中。\n\n创建一个xml配置扩展可以通过以下4步完成：\n\n1. 创建一个xml schema来描述你自定的xml元素。\n2. 编写一个`NamespaceHandler`的具体实现。\n3. 编写一个或者多个`BeanDefinitionParser`的实现。主要的工作都在此步骤完成。\n4. 关联`xsd`,`NamespaceHandler`。\n\n下面依照以上四个步骤并附一个示例详细讲解。完整代码放在码云上:https://git.oschina.net/android-speeder/springcustomxml.git\n\n<!-- more -->\n\n\n## 创建schema文件\n\n创建一个spring可以用的xml配置扩展首先需要定义一个xml schema来描述这个扩展。\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<xsd:schema xmlns=\"http://daveztong.github.io/schema/dz\"\n            xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\"\n            xmlns:beans=\"http://www.springframework.org/schema/beans\"\n            targetNamespace=\"http://daveztong.github.io/schema/dz\"\n            elementFormDefault=\"qualified\"\n            attributeFormDefault=\"unqualified\">\n\n    <xsd:import namespace=\"http://www.springframework.org/schema/beans\"/>\n\n    <xsd:element name=\"person\">\n        <xsd:complexType>\n            <xsd:complexContent>\n                <xsd:extension base=\"beans:identifiedType\">\n                    <xsd:attribute name=\"name\" type=\"xsd:string\" use=\"required\"/>\n                    <xsd:attribute name=\"age\" type=\"xsd:int\"/>\n                </xsd:extension>\n            </xsd:complexContent>\n        </xsd:complexType>\n    </xsd:element>\n\n</xsd:schema>\n```\n\n注意`<xsd:extension base=\"beans:identifiedType\">`表示该tag含有一个id属性并且会被spring container用于识别该bean。使用该属性的前提是需要导入`<xsd:import namespace=\"http://www.springframework.org/schema/beans\"/>`。\n\n\n\n## 实现NamespaceHandler\n\n当spring在解析xml时遇到该namespace就需要使用自定义的`Namespacehandler`去解析所有该名称空间下的元素。\n\n`NamespaceHandler`只包含三个方法:\n\n* `init()`: 用于初始化`NamespaceHandler`。\n* `BeanDefinition parse(Element, ParserContext)`：当spring遇到顶级的元素时才会调用。该方法可以直接返回一个bean definition或者自己注册一个。\n* `BeanDefinitionHolder decorate(Node, BeanDefinitionHolder, ParserContext)`:当spring遇到属性定义或者嵌套在不同名称空间下的元素时才会被调用。\n\n\n\n我们可以自己实现`NamespaceHandler`,但是基于spring的惯例，一般都会提供一个基础类简化开发人员的工作，所以我们可以直接继承spring提供的`NamespaceHandlerSupport`。\n\n```java\npackage io.github.daveztong;\n\nimport org.springframework.beans.factory.xml.NamespaceHandlerSupport;\n\n/**\n * Created by tangwei on 2016/10/31.\n */\npublic class DZNamespaceHandler extends NamespaceHandlerSupport{\n    @Override\n    public void init() {\n        registerBeanDefinitionParser(\"person\",new PersonBeanDefinitionParser());\n    }\n}\n```\n\n可以看到`DZNamespaceHandler`的代码量很少，因为真正的解析工作都委托给了`BeanDefinitionParser`。\t`NamespaceHandler`支持注册任意多个`BeanDefinitionParser`,当其需要解析其所负责的名称空间下的元素时就会将解析工作委托给注册的`BeanDefinitionParser`。\n\n## 实现`BeanDefinitionParser`\n\n当`NamespaceHandler`遇到一个与注册列表中key匹配的xml元素时就会将该元素的解析任务交给与key对应的`BeanDefinitionParser`。在本例中则是`PersonBeanDefinitionParser`。也就是说一个`BeanDefinitionParser`仅负责解析定义在指定schema中的一个唯一顶级的xml元素。在parser中我们可以访问到其负责解析的元素和子元素的内容。\n\n```java\npackage io.github.daveztong;\n\nimport org.springframework.beans.factory.support.BeanDefinitionBuilder;\nimport org.springframework.beans.factory.xml.AbstractSingleBeanDefinitionParser;\nimport org.springframework.util.StringUtils;\nimport org.w3c.dom.Element;\n\n/**\n * Created by tangwei on 2016/10/31.\n */\npublic class PersonBeanDefinitionParser extends AbstractSingleBeanDefinitionParser {\n    @Override\n    protected Class<?> getBeanClass(Element element) {\n        return Person.class;\n    }\n\n    @Override\n    protected void doParse(Element element, BeanDefinitionBuilder builder) {\n        String name = element.getAttribute(\"name\");\n        if (StringUtils.hasText(name)) {\n            builder.addPropertyValue(\"name\", name);\n        }\n\n        String age = element.getAttribute(\"age\");\n        if (StringUtils.hasText(age)) {\n            builder.addPropertyValue(\"age\", Integer.parseInt(age));\n        }\n    }\n}\n```\n\n编码部分就这么多，是不是so easy! 可能有人会疑问，为什么没有看到`BeanDefiniiton`的创建，那是因为创建的工作由`AbstractSingleBeanDefinitionParser#parseInternal`完成了。\n\n```java\n@Override\n\tprotected final AbstractBeanDefinition parseInternal(Element element, ParserContext parserContext) {\n\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition();\n\t\tString parentName = getParentName(element);\n\t\tif (parentName != null) {\n\t\t\tbuilder.getRawBeanDefinition().setParentName(parentName);\n\t\t}\n\t\tClass<?> beanClass = getBeanClass(element);\n\t\tif (beanClass != null) {\n\t\t\tbuilder.getRawBeanDefinition().setBeanClass(beanClass);\n\t\t}\n\t\telse {\n\t\t\tString beanClassName = getBeanClassName(element);\n\t\t\tif (beanClassName != null) {\n\t\t\t\tbuilder.getRawBeanDefinition().setBeanClassName(beanClassName);\n\t\t\t}\n\t\t}\n\t\tbuilder.getRawBeanDefinition().setSource(parserContext.extractSource(element));\n\t\tif (parserContext.isNested()) {\n\t\t\t// Inner bean definition must receive same scope as containing bean.\n\t\t\tbuilder.setScope(parserContext.getContainingBeanDefinition().getScope());\n\t\t}\n\t\tif (parserContext.isDefaultLazyInit()) {\n\t\t\t// Default-lazy-init applies to custom bean definitions as well.\n\t\t\tbuilder.setLazyInit(true);\n\t\t}\n\t\tdoParse(element, parserContext, builder);\n\t\treturn builder.getBeanDefinition();\n\t}\n```\n\nThe last statement `builder.getBeanDefinition();`返回了我们需要的bean. 继续看builder.getBeanDefinition()的代码:\n\n```java\npublic AbstractBeanDefinition getBeanDefinition() {\n\t\tthis.beanDefinition.validate();\n\t\treturn this.beanDefinition;\n\t}\n```\n\nThat's our bean!\n\n编码部分是完成了，但是spring还不知道他们的存在，接下来就需要让spring aware of them!(aware是个很关键的词啊，在spring的代码里随处可见^_^)\n\n\n\n## 注册handler and schema\n\n要让spring aware of out handler and xsd schema,我们需要在两个特殊的properties文件中注册他们。这些properties文件需要放在`META-INF`目录下面,并且可以和jar包一起发布。spring的解析框架通过这些特殊的properties文件就能pick up our handler and schema!\n\n\n\n### META-INF/spring.handlers\n\n`spring.handlers`包含了 xml schema uri 和namespace handler之间的k-v映射关系，如下:\n\n```properties\nhttp\\://daveztong.github.io/schema/dz=io.github.daveztong.DZNamespaceHandler\n```\n\n注意，因为`:`在properties文件中是个合法的分隔符，所以需要escape以下！\n\n其中URI部分是自定义的namespace扩展，必须与xsd中的`targetNamespace`完全匹配。\n\n### META-INF/spring.schemas\n\n`spring.schemas`中包含了xml schema uri(对应`xsi:schemaLocation`的值)与classpath resources的映射关系。如果这个文件不存在，spring默认会从网上加载`xsi:schemaLocation`中所定义的schema。有个这个映射文件，spring就会从classpath中加载而不再联网查找。\n\n```properties\nhttp\\://daveztong.github.io/schema/dz/dz.xsd=io/github/daveztong/schema/dz/dz.xsd\n```\n\n\n\n## Now,time to test\n\n使用xml定义person bean: spring-beans.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:dz=\"http://daveztong.github.io/schema/dz\"\n       xsi:schemaLocation=\"\nhttp://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\nhttp://daveztong.github.io/schema/dz http://daveztong.github.io/schema/dz/dz.xsd\">\n\n    <!-- as a top-level bean -->\n    <dz:person age=\"22\" id=\"person\" name=\"tangwei\"/>\n\n</beans>\n```\n\n\n\n为了演示效果，这里使用spring boot来快速测试: `App.java`\n\n```java\npackage io.github.daveztong;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.context.annotation.ImportResource;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\nimport javax.annotation.Resource;\n\n/**\n * Created by tangwei on 2016/11/1.\n */\n@EnableAutoConfiguration\n@Controller\n@ImportResource(\"classpath:spring-beans.xml\")\npublic class App {\n\n    @Resource\n    private Person person;\n\n    public static void main(String[] args) {\n        SpringApplication.run(App.class);\n    }\n\n    @RequestMapping(\"/\")\n    @ResponseBody\n    public String showPerson() {\n        return person.toString();\n    }\n}\n```\n\n\n\n访问http://localhost:8080/ ,dada:\n\n```\nPerson{age=22, name='tangwei'}\n```\n\n\n\n说了这么多，到底谁在用这个，能干啥呢！\n\n## Dubbo xml 配置扩展\n\nDubbo 在国内开源RPC界算是比较知名的，她其实采用的就是这种方式解析自定义的配置。dubbo jar 包结构:\n\n![dubbo jar structure](http://ww4.sinaimg.cn/large/94dc19degw1f9cgo55oetj209q06hmxg.jpg)\n\n\n\nspring.handlers:\n\n`http\\://code.alibabatech.com/schema/dubbo=com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler`\n\nspring.schemas:\n\n`http\\://code.alibabatech.com/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd`\n\nNamespaceHandler实现为:\n\n```java\npublic class DubboNamespaceHandler extends NamespaceHandlerSupport {\n\n\tstatic {\n\t\tVersion.checkDuplicate(DubboNamespaceHandler.class);\n\t}\n\n\tpublic void init() {\n\t    registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true));\n        registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true));\n        registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true));\n        registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true));\n        registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true));\n        registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true));\n        registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true));\n        registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true));\n        registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false));\n        registerBeanDefinitionParser(\"annotation\", new DubboBeanDefinitionParser(AnnotationBean.class, true));\n    }\n\n}\n```\n\n该handler注册了所有的bean definition parser!\n\n了解这种机制后，我们也可以根据自己需要做任何配置扩展。So cool!\n","slug":"Spring可扩展的XML配置","published":1,"updated":"2016-11-24T09:50:52.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fngz000ngm09eeksth9f"},{"title":"RESTAPI-Reference","date":"2016-02-03T04:00:41.000Z","_content":"\n最近在研究RESTAPI相关的一些最佳实践,搜集到一些不错的参考资料,备份一下。\n\n1. Wiki: Representational state transfer https://en.wikipedia.org/wiki/Representational_state_transfer#RESTful_web_services\n1. 来自HeroKu的HTTP API 设计指南(中文版) http://www.kancloud.cn/thinkphp/http-api-design/31119\n1. 理解RESTFul架构 http://mccxj.github.io/blog/20130530_introduce-to-rest.html\n1. Github API Reference https://developer.github.com/v3/\n1. Restful Web API 系列篇 http://www.cnblogs.com/artech/p/restful-web-api-02.html\n1. 理解本真的REST架构风格-来自InfoQ http://www.infoq.com/cn/articles/understanding-restful-style/\n","source":"_posts/RESTAPI-Reference.md","raw":"---\ntitle: RESTAPI-Reference\ndate: 2016-02-03 12:00:41\ntags: REST\n---\n\n最近在研究RESTAPI相关的一些最佳实践,搜集到一些不错的参考资料,备份一下。\n\n1. Wiki: Representational state transfer https://en.wikipedia.org/wiki/Representational_state_transfer#RESTful_web_services\n1. 来自HeroKu的HTTP API 设计指南(中文版) http://www.kancloud.cn/thinkphp/http-api-design/31119\n1. 理解RESTFul架构 http://mccxj.github.io/blog/20130530_introduce-to-rest.html\n1. Github API Reference https://developer.github.com/v3/\n1. Restful Web API 系列篇 http://www.cnblogs.com/artech/p/restful-web-api-02.html\n1. 理解本真的REST架构风格-来自InfoQ http://www.infoq.com/cn/articles/understanding-restful-style/\n","slug":"RESTAPI-Reference","published":1,"updated":"2016-02-03T04:50:25.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fnh1000qgm099ubiwana"},{"title":"Git查看、删除、重命名远程分支和tag","date":"2016-02-02T03:49:33.000Z","nicename":"delete_git_remote_branch","_content":"\n# Outline\n1. 查看远程分支\n1. 删除远程分支和tag\n1. 删除不存在对应远程分支的本地分支\n1. 重命名远程分支\n1. 把本地tag推送到远程\n1. 获取远程tag\n\n<!-- more -->\n\n## 查看远程分支\n\n加上-a参数可以查看远程分支，远程分支会用红色表示出来（如果你开了颜色支持的话）：\n\n``` bash\n$ git branch -a\n  master\n  remote\n  tungway\n  v1.52\n* zrong\n  remotes/origin/master\n  remotes/origin/tungway\n  remotes/origin/v1.52\n  remotes/origin/zrong\n```\n\n## 删除远程分支和tag\n\n在Git v1.7.0 之后，可以使用这种语法删除远程分支：\n\n``` bash\n$ git push origin --delete <branchName>\n```\n\n删除tag这么用：\n\n``` bash\ngit push origin --delete tag <tagname>\n```\n\n<!--more-->\n否则，可以使用这种语法，推送一个空分支到远程分支，其实就相当于删除远程分支：\n\n``` bash\ngit push origin :<branchName>\n```\n\n这是删除tag的方法，推送一个空tag到远程tag：\n\n``` bash\ngit tag -d <tagname>\ngit push origin :refs/tags/<tagname>\n```\n\n两种语法作用完全相同。\n\n## 删除不存在对应远程分支的本地分支\n\n假设这样一种情况：\n\n1. 我创建了本地分支b1并pull到远程分支 `origin/b1`；\n2. 其他人在本地使用fetch或pull创建了本地的b1分支；\n3. 我删除了 `origin/b1` 远程分支；\n4. 其他人再次执行fetch或者pull并不会删除这个他们本地的 `b1` 分支，运行 `git branch -a` 也不能看出这个branch被删除了，如何处理？\n\n使用下面的代码查看b1的状态：\n\n``` bash\n$ git remote show origin\n* remote origin\n  Fetch URL: git@github.com:xxx/xxx.git\n  Push  URL: git@github.com:xxx/xxx.git\n  HEAD branch: master\n  Remote branches:\n    master                 tracked\n    refs/remotes/origin/b1 stale (use 'git remote prune' to remove)\n  Local branch configured for 'git pull':\n    master merges with remote master\n  Local ref configured for 'git push':\n    master pushes to master (up to date)\n```\n\n这时候能够看到b1是stale的，使用 `git remote prune origin` 可以将其从本地版本库中去除。\n\n更简单的方法是使用这个命令，它在fetch之后删除掉没有与远程分支对应的本地分支：\n\n``` bash\ngit fetch -p\n```\n\n## 重命名远程分支\n\n在git中重命名远程分支，其实就是先删除远程分支，然后重命名本地分支，再重新提交一个远程分支。\n\n例如下面的例子中，我需要把 devel 分支重命名为 develop 分支：\n\n``` bash\n$ git branch -av\n* devel                             752bb84 Merge pull request #158 from Gwill/devel\n  master                            53b27b8 Merge pull request #138 from tdlrobin/master\n  zrong                             2ae98d8 modify CCFileUtils, export getFileData\n  remotes/origin/HEAD               -> origin/master\n  remotes/origin/add_build_script   d4a8c4f Merge branch 'master' into add_build_script\n  remotes/origin/devel              752bb84 Merge pull request #158 from Gwill/devel\n  remotes/origin/devel_qt51         62208f1 update .gitignore\n  remotes/origin/master             53b27b8 Merge pull request #138 from tdlrobin/master\n  remotes/origin/zrong              2ae98d8 modify CCFileUtils, export getFileData\n```\n\n删除远程分支：\n\n``` bash\n$ git push --delete origin devel\nTo git@github.com:zrong/quick-cocos2d-x.git\n - [deleted]         devel\n```\n\n重命名本地分支：\n\n``` bash\ngit branch -m devel develop\n```\n\n推送本地分支：\n\n``` bash\n$ git push origin develop\nCounting objects: 92, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (48/48), done.\nWriting objects: 100% (58/58), 1.38 MiB, done.\nTotal 58 (delta 34), reused 12 (delta 5)\nTo git@github.com:zrong/quick-cocos2d-x.git\n * [new branch]      develop -> develop\n```\n\n然而，在 github 上操作的时候，我在删除远程分支时碰到这个错误：\n\n``` bash\n$ git push --delete origin devel\nremote: error: refusing to delete the current branch: refs/heads/devel\nTo git@github.com:zrong/quick-cocos2d-x.git\n ! [remote rejected] devel (deletion of the current branch prohibited)\nerror: failed to push some refs to 'git@github.com:zrong/quick-cocos2d-x.git'\n```\n\n这是由于在 github 中，devel 是项目的默认分支。要解决此问题，这样操作：\n\n1. 进入 github 中该项目的 Settings 页面；\n2. 设置 Default Branch 为其他的分支（例如 master）；\n3. 重新执行删除远程分支命令。\n\n## 把本地tag推送到远程\n\n``` bash\ngit push --tags\n```\n\n## 获取远程tag\n\n``` bash\ngit fetch origin tag <tagname>\n```\n\n## 参考文章\n\n* <https://makandracards.com/makandra/621-git-delete-a-branch-local-or-remote>\n* <http://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-branch-both-locally-and-in-github>\n* <http://www.cnblogs.com/deepnighttwo/archive/2011/06/18/2084438.html>\n* <http://stackoverflow.com/questions/14040754/deleting-remote-master-branch-refused-due-to-being-current-branch>\n* <http://weli.iteye.com/blog/1441582>\n* <http://zengrong.net/post/1746.htm>\n","source":"_posts/Git查看、删除、重命名远程分支和tag.md","raw":"---\ntitle: Git查看、删除、重命名远程分支和tag\ndate: 2016-02-02 11:49:33\nnicename: delete_git_remote_branch\ncategory: git\ntags: git\n---\n\n# Outline\n1. 查看远程分支\n1. 删除远程分支和tag\n1. 删除不存在对应远程分支的本地分支\n1. 重命名远程分支\n1. 把本地tag推送到远程\n1. 获取远程tag\n\n<!-- more -->\n\n## 查看远程分支\n\n加上-a参数可以查看远程分支，远程分支会用红色表示出来（如果你开了颜色支持的话）：\n\n``` bash\n$ git branch -a\n  master\n  remote\n  tungway\n  v1.52\n* zrong\n  remotes/origin/master\n  remotes/origin/tungway\n  remotes/origin/v1.52\n  remotes/origin/zrong\n```\n\n## 删除远程分支和tag\n\n在Git v1.7.0 之后，可以使用这种语法删除远程分支：\n\n``` bash\n$ git push origin --delete <branchName>\n```\n\n删除tag这么用：\n\n``` bash\ngit push origin --delete tag <tagname>\n```\n\n<!--more-->\n否则，可以使用这种语法，推送一个空分支到远程分支，其实就相当于删除远程分支：\n\n``` bash\ngit push origin :<branchName>\n```\n\n这是删除tag的方法，推送一个空tag到远程tag：\n\n``` bash\ngit tag -d <tagname>\ngit push origin :refs/tags/<tagname>\n```\n\n两种语法作用完全相同。\n\n## 删除不存在对应远程分支的本地分支\n\n假设这样一种情况：\n\n1. 我创建了本地分支b1并pull到远程分支 `origin/b1`；\n2. 其他人在本地使用fetch或pull创建了本地的b1分支；\n3. 我删除了 `origin/b1` 远程分支；\n4. 其他人再次执行fetch或者pull并不会删除这个他们本地的 `b1` 分支，运行 `git branch -a` 也不能看出这个branch被删除了，如何处理？\n\n使用下面的代码查看b1的状态：\n\n``` bash\n$ git remote show origin\n* remote origin\n  Fetch URL: git@github.com:xxx/xxx.git\n  Push  URL: git@github.com:xxx/xxx.git\n  HEAD branch: master\n  Remote branches:\n    master                 tracked\n    refs/remotes/origin/b1 stale (use 'git remote prune' to remove)\n  Local branch configured for 'git pull':\n    master merges with remote master\n  Local ref configured for 'git push':\n    master pushes to master (up to date)\n```\n\n这时候能够看到b1是stale的，使用 `git remote prune origin` 可以将其从本地版本库中去除。\n\n更简单的方法是使用这个命令，它在fetch之后删除掉没有与远程分支对应的本地分支：\n\n``` bash\ngit fetch -p\n```\n\n## 重命名远程分支\n\n在git中重命名远程分支，其实就是先删除远程分支，然后重命名本地分支，再重新提交一个远程分支。\n\n例如下面的例子中，我需要把 devel 分支重命名为 develop 分支：\n\n``` bash\n$ git branch -av\n* devel                             752bb84 Merge pull request #158 from Gwill/devel\n  master                            53b27b8 Merge pull request #138 from tdlrobin/master\n  zrong                             2ae98d8 modify CCFileUtils, export getFileData\n  remotes/origin/HEAD               -> origin/master\n  remotes/origin/add_build_script   d4a8c4f Merge branch 'master' into add_build_script\n  remotes/origin/devel              752bb84 Merge pull request #158 from Gwill/devel\n  remotes/origin/devel_qt51         62208f1 update .gitignore\n  remotes/origin/master             53b27b8 Merge pull request #138 from tdlrobin/master\n  remotes/origin/zrong              2ae98d8 modify CCFileUtils, export getFileData\n```\n\n删除远程分支：\n\n``` bash\n$ git push --delete origin devel\nTo git@github.com:zrong/quick-cocos2d-x.git\n - [deleted]         devel\n```\n\n重命名本地分支：\n\n``` bash\ngit branch -m devel develop\n```\n\n推送本地分支：\n\n``` bash\n$ git push origin develop\nCounting objects: 92, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (48/48), done.\nWriting objects: 100% (58/58), 1.38 MiB, done.\nTotal 58 (delta 34), reused 12 (delta 5)\nTo git@github.com:zrong/quick-cocos2d-x.git\n * [new branch]      develop -> develop\n```\n\n然而，在 github 上操作的时候，我在删除远程分支时碰到这个错误：\n\n``` bash\n$ git push --delete origin devel\nremote: error: refusing to delete the current branch: refs/heads/devel\nTo git@github.com:zrong/quick-cocos2d-x.git\n ! [remote rejected] devel (deletion of the current branch prohibited)\nerror: failed to push some refs to 'git@github.com:zrong/quick-cocos2d-x.git'\n```\n\n这是由于在 github 中，devel 是项目的默认分支。要解决此问题，这样操作：\n\n1. 进入 github 中该项目的 Settings 页面；\n2. 设置 Default Branch 为其他的分支（例如 master）；\n3. 重新执行删除远程分支命令。\n\n## 把本地tag推送到远程\n\n``` bash\ngit push --tags\n```\n\n## 获取远程tag\n\n``` bash\ngit fetch origin tag <tagname>\n```\n\n## 参考文章\n\n* <https://makandracards.com/makandra/621-git-delete-a-branch-local-or-remote>\n* <http://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-branch-both-locally-and-in-github>\n* <http://www.cnblogs.com/deepnighttwo/archive/2011/06/18/2084438.html>\n* <http://stackoverflow.com/questions/14040754/deleting-remote-master-branch-refused-due-to-being-current-branch>\n* <http://weli.iteye.com/blog/1441582>\n* <http://zengrong.net/post/1746.htm>\n","slug":"Git查看、删除、重命名远程分支和tag","published":1,"updated":"2016-11-24T09:51:27.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fnh4000sgm094v0ekjpp"},{"title":"Dubbo学习-理解动态代理","date":"2016-11-23T14:38:15.000Z","_content":"\n# Dubbo学习-理解动态代理\n\n\n\n在之前的一篇post中了解了[spring可扩展的XML配置](http://daveztong.github.io/2016/11/01/Spring%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84XML%E9%85%8D%E7%BD%AE/)是怎么一会事，接下来继续研究dubbo consumer端如何解析service并执行远程调用。\n\n## 本次研究目标\n\n1. 代理如何创建的。仅仅只是配置了`<dubbo:reference interface=\"x.y.z.ServiceInterface\" id=\"serviceId\"/>`并将其交给了spring container，然后直接注入并使用该接口的方法就可以完成调用了，然而我并没有为该接口实现具体的类，how does it works? \n2. ~~远程调用如何执行的。假设已经有了具体的实现类，怎么实现远程调用的呢，Thingking?~~ 由于第一个分析就很长，这个目标列入下一次分析。\n\n<!-- more -->\n\n## 预备知识\n\n为了顺利的研究上述两个目标，需要了解以下知识:\n\n1. SPI. [官方教程](https://docs.oracle.com/javase/tutorial/ext/basics/spi.html)。用于服务扩展。\n2. Netty. [User Guide](http://netty.io/wiki/user-guide-for-4.x.html)。用于远程调用。\n3. Javassist. [官方Tutorial](https://jboss-javassist.github.io/javassist/tutorial/tutorial.html)。动态类生成。\n\n\n\n## How to dig in?\n\n从何处入手是个问题，我的习惯是顺藤摸瓜，所以从service被注入开始:\n\ndubbo service配置:\n\n```xml\n<!-- DemoService is just a interface -->\n<dubbo:reference interface=\"x.y.z.DemoService\" id=\"demoService\"/>\n```\n\nService注入:\n\n```java\n@Resource\nprivate DemoService demoService;\n```\n\n当使用这个`demoService`的时候可以肯定的是一定有个DemoService的具体实现可供使用，`DubboNamespaceHandler`中有这样一段代码:\n\n```java\nregisterBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class,false));\n```\n\n解析上面配置在namespace dubbo下的reference。`DubboBeanDefinitionParser`相关代码如下:\n\n```java\npublic DubboBeanDefinitionParser(Class<?> beanClass, boolean required) {\n  this.beanClass = beanClass;\n  this.required = required;\n}\n\npublic BeanDefinition parse(Element element, ParserContext parserContext) {\n  return parse(element, parserContext, beanClass, required);\n}\n\n// 关键部分\nprivate static BeanDefinition parse(Element element, ParserContext parserContext, Class<?> beanClass, boolean required) {\n    RootBeanDefinition beanDefinition = new RootBeanDefinition();\n    // 设置bean class,in this case it is ReferenceBean.class\n    beanDefinition.setBeanClass(beanClass);\n    beanDefinition.setLazyInit(false);\n    String id = element.getAttribute(\"id\");\n    // some ops...\n    if (id != null && id.length() > 0) {\n        if (parserContext.getRegistry().containsBeanDefinition(id))  {\n            throw new IllegalStateException(\"Duplicate spring bean id \" + id);\n        }\n        parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);\n        beanDefinition.getPropertyValues().addPropertyValue(\"id\", id);\n    }\n    \n    // some ops...\n\n    // 遍历setter and getter设置属性值\n    for (Method setter : beanClass.getMethods()) {\n        String name = setter.getName();\n        if (name.length() > 3 && name.startsWith(\"set\")\n                && Modifier.isPublic(setter.getModifiers())\n                && setter.getParameterTypes().length == 1) {\n            Class<?> type = setter.getParameterTypes()[0];\n            String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), \"-\");\n            if(...){\n                // some ops...\n            }else {\n                String value = element.getAttribute(property);\n                if (value != null) {\n                    value = value.trim();\n                    if (value.length() > 0) {\n                           // 部分省略...\n                            Object reference;\n                            if (isPrimitive(type)) {\n                                if (\"async\".equals(property) && \"false\".equals(value)\n                                        || \"timeout\".equals(property) && \"0\".equals(value)\n                                        || \"delay\".equals(property) && \"0\".equals(value)\n                                        || \"version\".equals(property) && \"0.0.0\".equals(value)\n                                        || \"stat\".equals(property) && \"-1\".equals(value)\n                                        || \"reliable\".equals(property) && \"false\".equals(value)) {\n                                    // 兼容旧版本xsd中的default值\n                                    value = null;\n                                }\n                                reference = value;\n                            } \n\n                            // 大批省略...\n\n                            // 这里会将interface这个attribute的值设置在ReferenceBean的父类ReferenceConfig的interfaceName上通过method:setInterface(String)\n                            beanDefinition.getPropertyValues().addPropertyValue(property, reference);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    // 省略...\n    return beanDefinition;\n}\n```\n\n上面两个关键的属性值id,interface都设置在了bean上，后面会用到。ReferenceConfig中的settter:setInterface用来设置interface：\n\n```java\npublic void setInterface(String interfaceName) {\n        this.interfaceName = interfaceName;\n        if (id == null || id.length() == 0) {\n            id = interfaceName;\n        }\n    }\n```\n\n参考ReferenceBean Hierarchy:\n\n![ReferenceBean Hierarchy](http://ww1.sinaimg.cn/mw690/50508d62gw1fa1b4h76xgj21960van07.jpg)\n\n\n\nReferenceBean中包含以几个两个方法:\n\n```java\n@Override\n// inherit from ApplicationContextAware\npublic void setApplicationContext(ApplicationContext applicationContext) {\n  this.applicationContext = applicationContext;\n  SpringExtensionFactory.addApplicationContext(applicationContext);\n}\n\n@Override\n// inherit from FactoryBean\npublic Object getObject() throws Exception {\n  return get();// 调用ReferenceConfig#get()方法创建类型为getObjectType()的对象，which in this case is instance of x.y.z.DemoService\n}\n// inherit from FactoryBean\npublic Class<?> getObjectType() {\n  return getInterfaceClass();\n}\n```\n\n如此，重点关注ReferenceConfig#get(),follow up:\n\n```java\npublic synchronized T get() {\n  if (destroyed){\n    throw new IllegalStateException(\"Already destroyed!\");\n  }\n  if (ref == null) {\n    init();\n  }\n  return ref;\n}\n```\n\n进入init():\n\n```java\nprivate void init() {\n    // some ops...\n     {\n        try {\n            // 之前设置的interface:x.y.z.DemoService\n            interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                    .getContextClassLoader());\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        checkInterfaceAndMethods(interfaceClass, methods);\n    }\n    // a lot of ops...\n    ref = createProxy(map);\n}\n```\n\n进入createProxy(Map):\n\n```java\nprivate T createProxy(Map<String, String> map) {\n    //some ops...\n\n    if (urls.size() == 1) {\n        invoker = refprotocol.refer(interfaceClass, urls.get(0));\n    } \n\n    // some ops...\n\n    // 创建服务代理\n    return (T) proxyFactory.getProxy(invoker);\n}\n```\n\n到这里已经知道代理是由ProxyFactory创建了，接下重点看看ProxyFactory.\n\n## ProxyFactory\n\nProxyFactory  Hierarchy:\n\n![ProxyFactory Hierarchy](http://ww4.sinaimg.cn/mw690/50508d62gw1fa27gqakyxj20l8080gmy.jpg)\n\n\n\n\n\n### AbstractProxyFactory\n\n```java\npublic <T> T getProxy(Invoker<T> invoker) throws RpcException {\n  Class<?>[] interfaces = null;\n  // createProxy时创建invoker时已将interface传入\n  String config = invoker.getUrl().getParameter(\"interfaces\");\n  if (config != null && config.length() > 0) {\n    String[] types = Constants.COMMA_SPLIT_PATTERN.split(config);\n    if (types != null && types.length > 0) {\n      interfaces = new Class<?>[types.length + 2];\n      interfaces[0] = invoker.getInterface();\n      interfaces[1] = EchoService.class;\n      for (int i = 0; i < types.length; i ++) {\n        interfaces[i + 1] = ReflectUtils.forName(types[i]);\n      }\n    }\n  }\n  if (interfaces == null) {\n    interfaces = new Class<?>[] {invoker.getInterface(), EchoService.class};\n  }\n  // 调用子类的实现\n  return getProxy(invoker, interfaces);\n```\n\n### JavassistProxyFactory\n\n```java\npublic <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {\n    return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));\n}\n```\n\n`getProxy`的相关代码:\n\n```java\npublic static Proxy getProxy(Class<?>... ics)\n{\n  return getProxy(ClassHelper.getCallerClassLoader(Proxy.class), ics);\n}\n```\n\n动态类的实现:\n\n```java\npublic static Proxy getProxy(ClassLoader cl, Class<?>... ics)\n    {\n        //some ops...\n        try\n        {\n            ccp = ClassGenerator.newInstance(cl);\n\n            Set<String> worked = new HashSet<String>();\n            List<Method> methods = new ArrayList<Method>();\n\n            // 反射获取interface的相关信息并build code string，然后交给javassist动态生成实现类。\n            for(int i=0;i<ics.length;i++)\n            {\n                if( !Modifier.isPublic(ics[i].getModifiers()) )\n                {\n                    String npkg = ics[i].getPackage().getName();\n                    if( pkg == null )\n                    {\n                        pkg = npkg;\n                    }\n                    else\n                    {\n                        if( !pkg.equals(npkg)  )\n                            throw new IllegalArgumentException(\"non-public interfaces from different packages\");\n                    }\n                }\n                ccp.addInterface(ics[i]);\n\n                for( Method method : ics[i].getMethods() )\n                {\n                    String desc = ReflectUtils.getDesc(method);\n                    if( worked.contains(desc) )\n                        continue;\n                    worked.add(desc);\n\n                    int ix = methods.size();\n                    Class<?> rt = method.getReturnType();\n                    Class<?>[] pts = method.getParameterTypes();\n\n                    StringBuilder code = new StringBuilder(\"Object[] args = new Object[\").append(pts.length).append(\"];\");\n                    for(int j=0;j<pts.length;j++)\n                        code.append(\" args[\").append(j).append(\"] = ($w)$\").append(j+1).append(\";\");\n                    // 注意这里 handler.invoke(),代理的统一处理\n                    code.append(\" Object ret = handler.invoke(this, methods[\" + ix + \"], args);\");\n                    if( !Void.TYPE.equals(rt) )\n                        code.append(\" return \").append(asArgument(rt, \"ret\")).append(\";\");\n\n                    methods.add(method);\n                    ccp.addMethod(method.getName(), method.getModifiers(), rt, pts, method.getExceptionTypes(), code.toString());\n                }\n            }\n\n            if( pkg == null )\n                pkg = PACKAGE_NAME;\n\n            // 接口的实现类\n            String pcn = pkg + \".proxy\" + id;\n            ccp.setClassName(pcn);\n            ccp.addField(\"public static java.lang.reflect.Method[] methods;\");\n            ccp.addField(\"private \" + InvocationHandler.class.getName() + \" handler;\");\n            ccp.addConstructor(Modifier.PUBLIC, new Class<?>[]{ InvocationHandler.class }, new Class<?>[0], \"handler=$1;\"); // $1等表示传入的参数，具体参考javassist官方文档\n            ccp.addDefaultConstructor();\n            Class<?> clazz = ccp.toClass();\n            clazz.getField(\"methods\").set(null, methods.toArray(new Method[0]));\n\n            // 生成当前Proxy的子类，实现newInstance()方法\n            String fcn = Proxy.class.getName() + id;\n            ccm = ClassGenerator.newInstance(cl);\n            ccm.setClassName(fcn);\n            ccm.addDefaultConstructor();\n            ccm.setSuperClass(Proxy.class);\n            ccm.addMethod(\"public Object newInstance(\" + InvocationHandler.class.getName() + \" h){ return new \" + pcn + \"($1); }\");\n            Class<?> pc = ccm.toClass();\n            proxy = (Proxy)pc.newInstance();\n        }\n        // some ops...\n        return proxy;\n    }\n```\n\n`toClass()` 为ClassGenerator的方法，实现也是通过javassist生成动态类。 这儿返回的是Proxy的子类实例。JavassistProxyFactory的getProxy中`Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));`这儿的newInstance()就属于这个子类实例。该方法的定义：\n\n```java\nabstract public Object newInstance(InvocationHandler handler);\n```\n\n再来看看InvocationHandler的实现:\n\n```java\npublic class InvokerInvocationHandler implements InvocationHandler {\n\n    private final Invoker<?> invoker;\n    \n    public InvokerInvocationHandler(Invoker<?> handler){\n        this.invoker = handler;\n    }\n\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        String methodName = method.getName();\n        Class<?>[] parameterTypes = method.getParameterTypes();\n        if (method.getDeclaringClass() == Object.class) {\n            return method.invoke(invoker, args);\n        }\n        if (\"toString\".equals(methodName) && parameterTypes.length == 0) {\n            return invoker.toString();\n        }\n        if (\"hashCode\".equals(methodName) && parameterTypes.length == 0) {\n            return invoker.hashCode();\n        }\n        if (\"equals\".equals(methodName) && parameterTypes.length == 1) {\n            return invoker.equals(args[0]);\n        }\n        // 返回远程调用的结果\n        return invoker.invoke(new RpcInvocation(method, args)).recreate();\n    }\n\n}\n```\n\n看到这儿可能还有点迷糊，invoke是在哪里调用的呢？回头看看动态类生成部分有这样一段代码:\n\n`code.append(\" Object ret = handler.invoke(this, methods[\" + ix + \"], args);\");`这就将代理调用衔接起来了。看起来可能有点抽象，待下面来试验一把。\n\n\n\n#### 试验\n\n`DemoService.java`\n\n```java\npackage com.alibaba.dubbo.examples.x.y.z;\n\n/**\n * Created by tangwei on 2016/11/23.\n */\npublic interface DemoService {\n    void sayHi(String name);\n}\n```\n\nMain.java\n\n```java\npackage com.alibaba.dubbo.examples.demo;\n\nimport com.alibaba.dubbo.common.URL;\nimport com.alibaba.dubbo.examples.x.y.z.DemoService;\nimport com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory;\nimport com.alibaba.dubbo.rpc.support.MockInvoker;\n\n/**\n * Created by tangwei on 2016/11/22.\n */\npublic class Main {\n    public static void main(String[] args) {\n        new JavassistProxyFactory().getProxy(new MockInvoker<DemoService>(new URL(\"\", \"\", 8888)),\n                new Class[]{DemoService.class});\n\n    }\n}\n```\n\n在`ClassGenerator`中 toClass返回前加入以下代码:\n\n```java\ntry {\n  // 将class写入文件\n  mCtc.writeFile(\"/path/to/save/classfile/\"+mSuperClass);\n} catch (IOException e) {\n  e.printStackTrace();\n}\n\nreturn mCtc.toClass(loader, pd);\n```\n\ndebug一下main,在动态生成类的时候将类写入文件中，结果如下：\n\nDemoService的实现:\n\n```java\n//\n// Source code recreated from a .class file by IntelliJ IDEA\n// (powered by Fernflower decompiler)\n//\n\npackage com.alibaba.dubbo.common.bytecode;\n\nimport com.alibaba.dubbo.common.bytecode.ClassGenerator.DC;\nimport com.alibaba.dubbo.examples.x.y.z.DemoService;\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\n\npublic class proxy0 implements DC, DemoService {\n    public static Method[] methods;\n    private InvocationHandler handler;\n\n    public void sayHi(String var1) {\n        Object[] var2 = new Object[]{var1};\n        this.handler.invoke(this, methods[0], var2);\n    }\n\n    public proxy0() {\n    }\n\n    public proxy0(InvocationHandler var1) {\n        this.handler = var1;\n    }\n}\n```\n\nProxy的子类:\n\n```java\n//\n// Source code recreated from a .class file by IntelliJ IDEA\n// (powered by Fernflower decompiler)\n//\n\npackage com.alibaba.dubbo.common.bytecode;\n\nimport com.alibaba.dubbo.common.bytecode.Proxy;\nimport com.alibaba.dubbo.common.bytecode.proxy0;\nimport com.alibaba.dubbo.common.bytecode.ClassGenerator.DC;\nimport java.lang.reflect.InvocationHandler;\n\npublic class Proxy0 extends Proxy implements DC {\n    public Object newInstance(InvocationHandler var1) {\n        // 返回的是DemoService的实例\n        return new proxy0(var1);\n    }\n\n    public Proxy0() {\n    }\n}\n```\n\n其中DC接口只是一个标识接口，表示该类是动态生成的。这样看起来就比较清晰明了了。下面再来看看jdk的proxy。\n\n### JdkProxyFactory\n\n相关代码如下:\n\n```java\npublic class JdkProxyFactory extends AbstractProxyFactory {\n\n    @SuppressWarnings(\"unchecked\")\n    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {\n        return (T) Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), interfaces, new InvokerInvocationHandler(invoker));\n    }\n\n    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {\n        return new AbstractProxyInvoker<T>(proxy, type, url) {\n            @Override\n            protected Object doInvoke(T proxy, String methodName, \n                                      Class<?>[] parameterTypes, \n                                      Object[] arguments) throws Throwable {\n                Method method = proxy.getClass().getMethod(methodName, parameterTypes);\n                return method.invoke(proxy, arguments);\n            }\n        };\n    }\n\n}\n```\n\n可以看到`Proxy.newProxyInstance`直接使用的是JDK的动态代理机制，因此就不再跟下去了。\n\n## 总结\n\n至此，对dubbo本地动态代理有一个清晰的理解了，总的来说一路顺藤摸瓜还算顺畅。对于选择哪一中方式作为生产使用，Dubbo推荐使用Javassist的代理机制，因为jdk原生的动态代理性能较差，生产环境不宜使用。","source":"_posts/Dubbo学习-理解动态代理.md","raw":"---\ntitle: Dubbo学习-理解动态代理\ndate: 2016-11-23 22:38:15\ncategories: dubbo\ntags: [dubbo,proxy,javassist]\n---\n\n# Dubbo学习-理解动态代理\n\n\n\n在之前的一篇post中了解了[spring可扩展的XML配置](http://daveztong.github.io/2016/11/01/Spring%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84XML%E9%85%8D%E7%BD%AE/)是怎么一会事，接下来继续研究dubbo consumer端如何解析service并执行远程调用。\n\n## 本次研究目标\n\n1. 代理如何创建的。仅仅只是配置了`<dubbo:reference interface=\"x.y.z.ServiceInterface\" id=\"serviceId\"/>`并将其交给了spring container，然后直接注入并使用该接口的方法就可以完成调用了，然而我并没有为该接口实现具体的类，how does it works? \n2. ~~远程调用如何执行的。假设已经有了具体的实现类，怎么实现远程调用的呢，Thingking?~~ 由于第一个分析就很长，这个目标列入下一次分析。\n\n<!-- more -->\n\n## 预备知识\n\n为了顺利的研究上述两个目标，需要了解以下知识:\n\n1. SPI. [官方教程](https://docs.oracle.com/javase/tutorial/ext/basics/spi.html)。用于服务扩展。\n2. Netty. [User Guide](http://netty.io/wiki/user-guide-for-4.x.html)。用于远程调用。\n3. Javassist. [官方Tutorial](https://jboss-javassist.github.io/javassist/tutorial/tutorial.html)。动态类生成。\n\n\n\n## How to dig in?\n\n从何处入手是个问题，我的习惯是顺藤摸瓜，所以从service被注入开始:\n\ndubbo service配置:\n\n```xml\n<!-- DemoService is just a interface -->\n<dubbo:reference interface=\"x.y.z.DemoService\" id=\"demoService\"/>\n```\n\nService注入:\n\n```java\n@Resource\nprivate DemoService demoService;\n```\n\n当使用这个`demoService`的时候可以肯定的是一定有个DemoService的具体实现可供使用，`DubboNamespaceHandler`中有这样一段代码:\n\n```java\nregisterBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class,false));\n```\n\n解析上面配置在namespace dubbo下的reference。`DubboBeanDefinitionParser`相关代码如下:\n\n```java\npublic DubboBeanDefinitionParser(Class<?> beanClass, boolean required) {\n  this.beanClass = beanClass;\n  this.required = required;\n}\n\npublic BeanDefinition parse(Element element, ParserContext parserContext) {\n  return parse(element, parserContext, beanClass, required);\n}\n\n// 关键部分\nprivate static BeanDefinition parse(Element element, ParserContext parserContext, Class<?> beanClass, boolean required) {\n    RootBeanDefinition beanDefinition = new RootBeanDefinition();\n    // 设置bean class,in this case it is ReferenceBean.class\n    beanDefinition.setBeanClass(beanClass);\n    beanDefinition.setLazyInit(false);\n    String id = element.getAttribute(\"id\");\n    // some ops...\n    if (id != null && id.length() > 0) {\n        if (parserContext.getRegistry().containsBeanDefinition(id))  {\n            throw new IllegalStateException(\"Duplicate spring bean id \" + id);\n        }\n        parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);\n        beanDefinition.getPropertyValues().addPropertyValue(\"id\", id);\n    }\n    \n    // some ops...\n\n    // 遍历setter and getter设置属性值\n    for (Method setter : beanClass.getMethods()) {\n        String name = setter.getName();\n        if (name.length() > 3 && name.startsWith(\"set\")\n                && Modifier.isPublic(setter.getModifiers())\n                && setter.getParameterTypes().length == 1) {\n            Class<?> type = setter.getParameterTypes()[0];\n            String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), \"-\");\n            if(...){\n                // some ops...\n            }else {\n                String value = element.getAttribute(property);\n                if (value != null) {\n                    value = value.trim();\n                    if (value.length() > 0) {\n                           // 部分省略...\n                            Object reference;\n                            if (isPrimitive(type)) {\n                                if (\"async\".equals(property) && \"false\".equals(value)\n                                        || \"timeout\".equals(property) && \"0\".equals(value)\n                                        || \"delay\".equals(property) && \"0\".equals(value)\n                                        || \"version\".equals(property) && \"0.0.0\".equals(value)\n                                        || \"stat\".equals(property) && \"-1\".equals(value)\n                                        || \"reliable\".equals(property) && \"false\".equals(value)) {\n                                    // 兼容旧版本xsd中的default值\n                                    value = null;\n                                }\n                                reference = value;\n                            } \n\n                            // 大批省略...\n\n                            // 这里会将interface这个attribute的值设置在ReferenceBean的父类ReferenceConfig的interfaceName上通过method:setInterface(String)\n                            beanDefinition.getPropertyValues().addPropertyValue(property, reference);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    // 省略...\n    return beanDefinition;\n}\n```\n\n上面两个关键的属性值id,interface都设置在了bean上，后面会用到。ReferenceConfig中的settter:setInterface用来设置interface：\n\n```java\npublic void setInterface(String interfaceName) {\n        this.interfaceName = interfaceName;\n        if (id == null || id.length() == 0) {\n            id = interfaceName;\n        }\n    }\n```\n\n参考ReferenceBean Hierarchy:\n\n![ReferenceBean Hierarchy](http://ww1.sinaimg.cn/mw690/50508d62gw1fa1b4h76xgj21960van07.jpg)\n\n\n\nReferenceBean中包含以几个两个方法:\n\n```java\n@Override\n// inherit from ApplicationContextAware\npublic void setApplicationContext(ApplicationContext applicationContext) {\n  this.applicationContext = applicationContext;\n  SpringExtensionFactory.addApplicationContext(applicationContext);\n}\n\n@Override\n// inherit from FactoryBean\npublic Object getObject() throws Exception {\n  return get();// 调用ReferenceConfig#get()方法创建类型为getObjectType()的对象，which in this case is instance of x.y.z.DemoService\n}\n// inherit from FactoryBean\npublic Class<?> getObjectType() {\n  return getInterfaceClass();\n}\n```\n\n如此，重点关注ReferenceConfig#get(),follow up:\n\n```java\npublic synchronized T get() {\n  if (destroyed){\n    throw new IllegalStateException(\"Already destroyed!\");\n  }\n  if (ref == null) {\n    init();\n  }\n  return ref;\n}\n```\n\n进入init():\n\n```java\nprivate void init() {\n    // some ops...\n     {\n        try {\n            // 之前设置的interface:x.y.z.DemoService\n            interfaceClass = Class.forName(interfaceName, true, Thread.currentThread()\n                    .getContextClassLoader());\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n        checkInterfaceAndMethods(interfaceClass, methods);\n    }\n    // a lot of ops...\n    ref = createProxy(map);\n}\n```\n\n进入createProxy(Map):\n\n```java\nprivate T createProxy(Map<String, String> map) {\n    //some ops...\n\n    if (urls.size() == 1) {\n        invoker = refprotocol.refer(interfaceClass, urls.get(0));\n    } \n\n    // some ops...\n\n    // 创建服务代理\n    return (T) proxyFactory.getProxy(invoker);\n}\n```\n\n到这里已经知道代理是由ProxyFactory创建了，接下重点看看ProxyFactory.\n\n## ProxyFactory\n\nProxyFactory  Hierarchy:\n\n![ProxyFactory Hierarchy](http://ww4.sinaimg.cn/mw690/50508d62gw1fa27gqakyxj20l8080gmy.jpg)\n\n\n\n\n\n### AbstractProxyFactory\n\n```java\npublic <T> T getProxy(Invoker<T> invoker) throws RpcException {\n  Class<?>[] interfaces = null;\n  // createProxy时创建invoker时已将interface传入\n  String config = invoker.getUrl().getParameter(\"interfaces\");\n  if (config != null && config.length() > 0) {\n    String[] types = Constants.COMMA_SPLIT_PATTERN.split(config);\n    if (types != null && types.length > 0) {\n      interfaces = new Class<?>[types.length + 2];\n      interfaces[0] = invoker.getInterface();\n      interfaces[1] = EchoService.class;\n      for (int i = 0; i < types.length; i ++) {\n        interfaces[i + 1] = ReflectUtils.forName(types[i]);\n      }\n    }\n  }\n  if (interfaces == null) {\n    interfaces = new Class<?>[] {invoker.getInterface(), EchoService.class};\n  }\n  // 调用子类的实现\n  return getProxy(invoker, interfaces);\n```\n\n### JavassistProxyFactory\n\n```java\npublic <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {\n    return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));\n}\n```\n\n`getProxy`的相关代码:\n\n```java\npublic static Proxy getProxy(Class<?>... ics)\n{\n  return getProxy(ClassHelper.getCallerClassLoader(Proxy.class), ics);\n}\n```\n\n动态类的实现:\n\n```java\npublic static Proxy getProxy(ClassLoader cl, Class<?>... ics)\n    {\n        //some ops...\n        try\n        {\n            ccp = ClassGenerator.newInstance(cl);\n\n            Set<String> worked = new HashSet<String>();\n            List<Method> methods = new ArrayList<Method>();\n\n            // 反射获取interface的相关信息并build code string，然后交给javassist动态生成实现类。\n            for(int i=0;i<ics.length;i++)\n            {\n                if( !Modifier.isPublic(ics[i].getModifiers()) )\n                {\n                    String npkg = ics[i].getPackage().getName();\n                    if( pkg == null )\n                    {\n                        pkg = npkg;\n                    }\n                    else\n                    {\n                        if( !pkg.equals(npkg)  )\n                            throw new IllegalArgumentException(\"non-public interfaces from different packages\");\n                    }\n                }\n                ccp.addInterface(ics[i]);\n\n                for( Method method : ics[i].getMethods() )\n                {\n                    String desc = ReflectUtils.getDesc(method);\n                    if( worked.contains(desc) )\n                        continue;\n                    worked.add(desc);\n\n                    int ix = methods.size();\n                    Class<?> rt = method.getReturnType();\n                    Class<?>[] pts = method.getParameterTypes();\n\n                    StringBuilder code = new StringBuilder(\"Object[] args = new Object[\").append(pts.length).append(\"];\");\n                    for(int j=0;j<pts.length;j++)\n                        code.append(\" args[\").append(j).append(\"] = ($w)$\").append(j+1).append(\";\");\n                    // 注意这里 handler.invoke(),代理的统一处理\n                    code.append(\" Object ret = handler.invoke(this, methods[\" + ix + \"], args);\");\n                    if( !Void.TYPE.equals(rt) )\n                        code.append(\" return \").append(asArgument(rt, \"ret\")).append(\";\");\n\n                    methods.add(method);\n                    ccp.addMethod(method.getName(), method.getModifiers(), rt, pts, method.getExceptionTypes(), code.toString());\n                }\n            }\n\n            if( pkg == null )\n                pkg = PACKAGE_NAME;\n\n            // 接口的实现类\n            String pcn = pkg + \".proxy\" + id;\n            ccp.setClassName(pcn);\n            ccp.addField(\"public static java.lang.reflect.Method[] methods;\");\n            ccp.addField(\"private \" + InvocationHandler.class.getName() + \" handler;\");\n            ccp.addConstructor(Modifier.PUBLIC, new Class<?>[]{ InvocationHandler.class }, new Class<?>[0], \"handler=$1;\"); // $1等表示传入的参数，具体参考javassist官方文档\n            ccp.addDefaultConstructor();\n            Class<?> clazz = ccp.toClass();\n            clazz.getField(\"methods\").set(null, methods.toArray(new Method[0]));\n\n            // 生成当前Proxy的子类，实现newInstance()方法\n            String fcn = Proxy.class.getName() + id;\n            ccm = ClassGenerator.newInstance(cl);\n            ccm.setClassName(fcn);\n            ccm.addDefaultConstructor();\n            ccm.setSuperClass(Proxy.class);\n            ccm.addMethod(\"public Object newInstance(\" + InvocationHandler.class.getName() + \" h){ return new \" + pcn + \"($1); }\");\n            Class<?> pc = ccm.toClass();\n            proxy = (Proxy)pc.newInstance();\n        }\n        // some ops...\n        return proxy;\n    }\n```\n\n`toClass()` 为ClassGenerator的方法，实现也是通过javassist生成动态类。 这儿返回的是Proxy的子类实例。JavassistProxyFactory的getProxy中`Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));`这儿的newInstance()就属于这个子类实例。该方法的定义：\n\n```java\nabstract public Object newInstance(InvocationHandler handler);\n```\n\n再来看看InvocationHandler的实现:\n\n```java\npublic class InvokerInvocationHandler implements InvocationHandler {\n\n    private final Invoker<?> invoker;\n    \n    public InvokerInvocationHandler(Invoker<?> handler){\n        this.invoker = handler;\n    }\n\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        String methodName = method.getName();\n        Class<?>[] parameterTypes = method.getParameterTypes();\n        if (method.getDeclaringClass() == Object.class) {\n            return method.invoke(invoker, args);\n        }\n        if (\"toString\".equals(methodName) && parameterTypes.length == 0) {\n            return invoker.toString();\n        }\n        if (\"hashCode\".equals(methodName) && parameterTypes.length == 0) {\n            return invoker.hashCode();\n        }\n        if (\"equals\".equals(methodName) && parameterTypes.length == 1) {\n            return invoker.equals(args[0]);\n        }\n        // 返回远程调用的结果\n        return invoker.invoke(new RpcInvocation(method, args)).recreate();\n    }\n\n}\n```\n\n看到这儿可能还有点迷糊，invoke是在哪里调用的呢？回头看看动态类生成部分有这样一段代码:\n\n`code.append(\" Object ret = handler.invoke(this, methods[\" + ix + \"], args);\");`这就将代理调用衔接起来了。看起来可能有点抽象，待下面来试验一把。\n\n\n\n#### 试验\n\n`DemoService.java`\n\n```java\npackage com.alibaba.dubbo.examples.x.y.z;\n\n/**\n * Created by tangwei on 2016/11/23.\n */\npublic interface DemoService {\n    void sayHi(String name);\n}\n```\n\nMain.java\n\n```java\npackage com.alibaba.dubbo.examples.demo;\n\nimport com.alibaba.dubbo.common.URL;\nimport com.alibaba.dubbo.examples.x.y.z.DemoService;\nimport com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory;\nimport com.alibaba.dubbo.rpc.support.MockInvoker;\n\n/**\n * Created by tangwei on 2016/11/22.\n */\npublic class Main {\n    public static void main(String[] args) {\n        new JavassistProxyFactory().getProxy(new MockInvoker<DemoService>(new URL(\"\", \"\", 8888)),\n                new Class[]{DemoService.class});\n\n    }\n}\n```\n\n在`ClassGenerator`中 toClass返回前加入以下代码:\n\n```java\ntry {\n  // 将class写入文件\n  mCtc.writeFile(\"/path/to/save/classfile/\"+mSuperClass);\n} catch (IOException e) {\n  e.printStackTrace();\n}\n\nreturn mCtc.toClass(loader, pd);\n```\n\ndebug一下main,在动态生成类的时候将类写入文件中，结果如下：\n\nDemoService的实现:\n\n```java\n//\n// Source code recreated from a .class file by IntelliJ IDEA\n// (powered by Fernflower decompiler)\n//\n\npackage com.alibaba.dubbo.common.bytecode;\n\nimport com.alibaba.dubbo.common.bytecode.ClassGenerator.DC;\nimport com.alibaba.dubbo.examples.x.y.z.DemoService;\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\n\npublic class proxy0 implements DC, DemoService {\n    public static Method[] methods;\n    private InvocationHandler handler;\n\n    public void sayHi(String var1) {\n        Object[] var2 = new Object[]{var1};\n        this.handler.invoke(this, methods[0], var2);\n    }\n\n    public proxy0() {\n    }\n\n    public proxy0(InvocationHandler var1) {\n        this.handler = var1;\n    }\n}\n```\n\nProxy的子类:\n\n```java\n//\n// Source code recreated from a .class file by IntelliJ IDEA\n// (powered by Fernflower decompiler)\n//\n\npackage com.alibaba.dubbo.common.bytecode;\n\nimport com.alibaba.dubbo.common.bytecode.Proxy;\nimport com.alibaba.dubbo.common.bytecode.proxy0;\nimport com.alibaba.dubbo.common.bytecode.ClassGenerator.DC;\nimport java.lang.reflect.InvocationHandler;\n\npublic class Proxy0 extends Proxy implements DC {\n    public Object newInstance(InvocationHandler var1) {\n        // 返回的是DemoService的实例\n        return new proxy0(var1);\n    }\n\n    public Proxy0() {\n    }\n}\n```\n\n其中DC接口只是一个标识接口，表示该类是动态生成的。这样看起来就比较清晰明了了。下面再来看看jdk的proxy。\n\n### JdkProxyFactory\n\n相关代码如下:\n\n```java\npublic class JdkProxyFactory extends AbstractProxyFactory {\n\n    @SuppressWarnings(\"unchecked\")\n    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {\n        return (T) Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), interfaces, new InvokerInvocationHandler(invoker));\n    }\n\n    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {\n        return new AbstractProxyInvoker<T>(proxy, type, url) {\n            @Override\n            protected Object doInvoke(T proxy, String methodName, \n                                      Class<?>[] parameterTypes, \n                                      Object[] arguments) throws Throwable {\n                Method method = proxy.getClass().getMethod(methodName, parameterTypes);\n                return method.invoke(proxy, arguments);\n            }\n        };\n    }\n\n}\n```\n\n可以看到`Proxy.newProxyInstance`直接使用的是JDK的动态代理机制，因此就不再跟下去了。\n\n## 总结\n\n至此，对dubbo本地动态代理有一个清晰的理解了，总的来说一路顺藤摸瓜还算顺畅。对于选择哪一中方式作为生产使用，Dubbo推荐使用Javassist的代理机制，因为jdk原生的动态代理性能较差，生产环境不宜使用。","slug":"Dubbo学习-理解动态代理","published":1,"updated":"2016-11-24T09:49:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civw7fnh7000xgm09ucom5kp9"}],"PostAsset":[],"PostCategory":[{"post_id":"civw7fngt000egm09p6q6kfm2","category_id":"civw7fngu000fgm09vumhx81k","_id":"civw7fngv000igm09ednfm44e"},{"post_id":"civw7fnh4000sgm094v0ekjpp","category_id":"civw7fnh5000tgm09fz8tl584","_id":"civw7fnh5000wgm09lraw2sze"},{"post_id":"civw7fnh7000xgm09ucom5kp9","category_id":"civw7fnh7000ygm090nt2guvz","_id":"civw7fnh80011gm09ixe98lh3"}],"PostTag":[{"post_id":"civw7fng60000gm0923ha6x56","tag_id":"civw7fngb0001gm09n0b9vauw","_id":"civw7fngc0002gm094a64ybcb"},{"post_id":"civw7fngo0006gm09om5rmwod","tag_id":"civw7fngp0007gm09pb0p18x6","_id":"civw7fngq0009gm09czw68zm9"},{"post_id":"civw7fngo0006gm09om5rmwod","tag_id":"civw7fngq0008gm09ekulzt5n","_id":"civw7fngq000agm09rvcer711"},{"post_id":"civw7fngq000bgm09y51au15s","tag_id":"civw7fngr000cgm094e7ttn68","_id":"civw7fngs000dgm09hfsxrs0h"},{"post_id":"civw7fngt000egm09p6q6kfm2","tag_id":"civw7fngu000ggm09sikja5wd","_id":"civw7fngv000hgm090pn8fn0w"},{"post_id":"civw7fngt000egm09p6q6kfm2","tag_id":"civw7fngp0007gm09pb0p18x6","_id":"civw7fngv000jgm0902m8z4y5"},{"post_id":"civw7fngw000kgm09yuw1li5s","tag_id":"civw7fngx000lgm09dxz9tx9w","_id":"civw7fngx000mgm091cfesj5y"},{"post_id":"civw7fngz000ngm09eeksth9f","tag_id":"civw7fnh0000ogm096yxhy17a","_id":"civw7fnh0000pgm09l35fr4q3"},{"post_id":"civw7fnh1000qgm099ubiwana","tag_id":"civw7fngb0001gm09n0b9vauw","_id":"civw7fnh2000rgm09orurxdgd"},{"post_id":"civw7fnh4000sgm094v0ekjpp","tag_id":"civw7fnh5000ugm09w1ufp60j","_id":"civw7fnh5000vgm09k9peil2k"},{"post_id":"civw7fnh7000xgm09ucom5kp9","tag_id":"civw7fnh0000ogm096yxhy17a","_id":"civw7fnh90012gm09gljh0aip"},{"post_id":"civw7fnh7000xgm09ucom5kp9","tag_id":"civw7fnh7000zgm09tw3slxoo","_id":"civw7fnh90013gm096mhtm8ty"},{"post_id":"civw7fnh7000xgm09ucom5kp9","tag_id":"civw7fnh80010gm0984d9av23","_id":"civw7fnh90014gm09avg77m9o"}],"Tag":[{"name":"REST","_id":"civw7fngb0001gm09n0b9vauw"},{"name":"java","_id":"civw7fngp0007gm09pb0p18x6"},{"name":"HashMap","_id":"civw7fngq0008gm09ekulzt5n"},{"name":"PM","_id":"civw7fngr000cgm094e7ttn68"},{"name":"effective","_id":"civw7fngu000ggm09sikja5wd"},{"name":"MySQL","_id":"civw7fngx000lgm09dxz9tx9w"},{"name":"dubbo","_id":"civw7fnh0000ogm096yxhy17a"},{"name":"git","_id":"civw7fnh5000ugm09w1ufp60j"},{"name":"proxy","_id":"civw7fnh7000zgm09tw3slxoo"},{"name":"javassist","_id":"civw7fnh80010gm0984d9av23"}]}}